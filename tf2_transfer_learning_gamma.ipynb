{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pablojrios/fluence_maps/blob/master/tf2_transfer_learning_gamma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRTa3Ee15WsJ"
   },
   "source": [
    "# Transfer learning with a pretrained ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wRK8ctZQIEuc"
   },
   "outputs": [],
   "source": [
    "def isGoogleColab():\n",
    "    # 'ipykernel.zmqshell' runs in our server\n",
    "    # 'google.colab._shell' runs in Google Colab\n",
    "    return get_ipython().__class__.__module__ == 'google.colab._shell'\n",
    "\n",
    "#import sys\n",
    "#import IPython\n",
    "\n",
    "#if 'ipykernel' in sys.modules:\n",
    "#    ip = sys.modules['ipykernel']\n",
    "#    ip_version = ip.version_info\n",
    "#    ip_client = ip.write_connection_file.__module__.split('.')[0]\n",
    "\n",
    "#ip_version, ip_client\n",
    "\n",
    "#ip_version = IPython.utils.sysinfo.get_sys_info()['ipython_version']\n",
    "#ip_version\n",
    "\n",
    "#if 'IPython' in sys.modules:\n",
    "#    ip = sys.modules['IPython']\n",
    "#    ip_version = ip.version_info\n",
    "#    print(ip_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iBMcobPHdD8O"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "from random import shuffle, randrange\n",
    "import random\n",
    "import tensorflow_addons as tfa\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version = 2.2.0, addons version = 0.10.0\n",
      "Executing eagerly = True\n",
      "OpenCV version = 3.4.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow version = {}, addons version = {}'.format(tf.__version__, tfa.__version__))\n",
    "print('Executing eagerly = {}'.format(tf.executing_eagerly()))\n",
    "keras = tf.keras\n",
    "\n",
    "import cv2 # to perform data augmentation\n",
    "print('OpenCV version = {}'.format(cv2.__version__))\n",
    "\n",
    "datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q50x39yF5BPt"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "if isGoogleColab():\n",
    "    %cd '/content'\n",
    "    if os.path.exists('fluence_maps'):\n",
    "      !rm -fr fluence_maps\n",
    "\n",
    "    ## Install required dependencies\n",
    "    !pip install -q pydicom\n",
    "    ## to support ResNet18 and ResNet34\n",
    "    !pip install image-classifiers\n",
    "    ## https://github.com/tensorflow/addons/issues/2251\n",
    "    !pip install -U tensorflow-addons\n",
    "\n",
    "    GIT_USERNAME = \"pablojrios\"\n",
    "    GIT_TOKEN = \"1d88a0b85d2b00a03796e4d8b7e5f7b249b12f9b\"\n",
    "    !git clone -s https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/fluence_maps.git\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    %cd -q '/content/fluence_maps'\n",
    "    \n",
    "    ARG_DATASET_DIR='/content/drive/My Drive/Healthcare/Radioterapia/data/ciolaplata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LhWAVjltIJWh"
   },
   "outputs": [],
   "source": [
    "# To support ResNet18 and ResNet34 for tensorflow.keras\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from util.preprocess import rescale_0_to_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Enum):\n",
    "        vgg16 = 1\n",
    "        resnet18 = 2\n",
    "        resnet34 = 3\n",
    "        mobilenetV2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uFuIiQp2zVUF"
   },
   "outputs": [],
   "source": [
    "# ===============================================DEFINE YOUR ARGUMENTS=================================================\n",
    "if not isGoogleColab():\n",
    "    ARG_DATASET_DIR='/hdd/data/radioterapia/ciolaplata'\n",
    "# folder under ARG_DATASET_DIR path.\n",
    "ARG_RANDOM_SEED = 23456\n",
    "# ARG_TFDATASET_FOLDER=f'tfds.2019-2018-2017.localnorm.DS10%.{ARG_RANDOM_SEED}.gammaGT95.undersampled.2000.fold1'\n",
    "# ARG_TFDATASET_FOLDER=f'tfds.2019-2017.localnorm.DS10%.{ARG_RANDOM_SEED}.jpeg100%.fold0'\n",
    "ARG_TFDATASET_FOLDER=f'tfds.2019-2017.localnorm.DS10%.{ARG_RANDOM_SEED}.fold0'\n",
    "# ARG_TFDATASET_FOLDER=f'tfds.2018.localnorm.DS10%.{ARG_RANDOM_SEED}.fold0'\n",
    "# if False only training and validation partition are created.\n",
    "ARG_TEST_PARTITION=False\n",
    "ARG_NETWORK=CNN.resnet18\n",
    "ARG_RESNET_USE_BN=True\n",
    "\n",
    "# number of continuous epochs without improvement on validation\n",
    "ARG_EPOCHS_WO_IMPROVEMENT=20 # 20 for 2019 only, 10 for 2019+2018, 30 for 2019+2018 for MobileNetV2\n",
    "initial_epochs = 10 # 10 for 2019 only, 5 for 2019+2018\n",
    "# maximum fine-tuning epochs\n",
    "ARG_MAX_FINE_TUNING_EPOCHS=200\n",
    "# 0: use custom LR, 1: use ReduceLROnPlateau\n",
    "ARG_LR_SCHEDULE=1\n",
    "ARG_LR_PATIENCE=10 # only applies if ARG_LR_SCHEDULE is 1. Equals to 10 except for MobileNetV2 that requires 15+\n",
    "ARG_MIN_DELTA_MAE=0.01\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "ARG_DATA_AUGMENTATION=False\n",
    "# perform data augmentation of images with a gamma value lower than gamma_augment\n",
    "ARG_GAMMA_AUGMENT=97.0\n",
    "# set this value based on the ARG_OVERSAMPLING_FACTOR value in tf2_oversampling_dicom_files.py\n",
    "# 1.0 means transform each and every image, with a lower value than 1.0 means that training will include unmodified (not transformed)\n",
    "# images.\n",
    "ARG_AUGMENT_PROBABILITY=0.75 # con 0.85 para el dataset tfds.2019.localnorm.ovs95x8.0 no transformo 93*(1+8)*0.15=125 imágenes  \n",
    "add_regularizers=False\n",
    "## Fine-tune from this layer onwards\n",
    "# fine_tune_at = 281 # InceptionV3, fine-tuning\n",
    "# fine_tune_at = 102 # InceptionV3, not so fine-tuning\n",
    "# fine_tune_at = 74 # resnet34 stage3\n",
    "# fine_tune_at = 129 # resnet34 stage4\n",
    "if ARG_NETWORK == CNN.vgg16:\n",
    "    fine_tune_at = 11 # VGG16\n",
    "elif ARG_NETWORK == CNN.resnet18:\n",
    "    fine_tune_at = 46 # resnet18 stage3\n",
    "    # fine_tune_at = 27 # resnet18 stage2\n",
    "elif ARG_NETWORK == CNN.resnet34:\n",
    "    fine_tune_at = 73 # resnet34 stage3\n",
    "else:\n",
    "    fine_tune_at = 117 # MobileNetV2 block_12_add para atrás\n",
    "ARG_TRANSFORM_GAMMA=False\n",
    "\n",
    "STANDARIZE_TARGET=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v77rlkCKW0IJ"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GoKGm1duzgk"
   },
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KVh7rDVAuW8Y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "tf.random.set_seed(ARG_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1KR9xb8NyFTC"
   },
   "outputs": [],
   "source": [
    "def _tfrecord_dataset_type_from_folder(folder, dataset_type, ext='.tfrecords'):\n",
    "    tfrecords = [os.path.join(folder, n)\n",
    "                 for n in os.listdir(folder) if n.startswith(dataset_type) and n.endswith(ext)]\n",
    "    return tf.data.TFRecordDataset(tfrecords)\n",
    "\n",
    "tfdataset_dir = os.path.join(ARG_DATASET_DIR, ARG_TFDATASET_FOLDER)\n",
    "# type(raw_train) is tensorflow.python.data.ops.readers.TFRecordDatasetV2\n",
    "raw_train = _tfrecord_dataset_type_from_folder(tfdataset_dir, 'train')\n",
    "raw_validation = _tfrecord_dataset_type_from_folder(tfdataset_dir, 'validation')\n",
    "if ARG_TEST_PARTITION:\n",
    "    raw_test = _tfrecord_dataset_type_from_folder(tfdataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o29EfE-p0g5X"
   },
   "source": [
    "The resulting `tf.data.Dataset` objects contain `(image, label)` pairs where the images have variable shape and 3 channels, and the label is a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GIys1_zY1S9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n",
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "if ARG_TEST_PARTITION:\n",
    "    print(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T1Gm1wdHyFTK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training part = 3414.\n",
      "Number of images in validation part = 854.\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of images in training part = {sum(1 for _ in raw_train)}.')\n",
    "print(f'Number of images in validation part = {sum(1 for _ in raw_validation)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ar8TNzTSyFTS"
   },
   "outputs": [],
   "source": [
    "def _parse_image_function(example_proto, img_size, normalization_fn, data_augmentation=False, augment_probability=1.0, transform_gamma=False,\n",
    "                         standarize_gamma=False, train_mean=0.0, train_stdev=1.0):\n",
    "    # Create a dictionary describing the features.\n",
    "    image_feature_description = {\"image/filename\": tf.io.FixedLenFeature((), tf.string),\n",
    "                \"image/encoded\": tf.io.FixedLenFeature((), tf.string),\n",
    "                \"image/format\": tf.io.FixedLenFeature((), tf.string),\n",
    "                \"image/gamma_index\": tf.io.FixedLenFeature((), tf.float32),\n",
    "                \"image/height\": tf.io.FixedLenFeature((), tf.int64),\n",
    "                \"image/width\": tf.io.FixedLenFeature((), tf.int64)}\n",
    "    \n",
    "    def image_augment(image):\n",
    "        radian = ((np.random.random()-.50)*10 / 360) * np.pi\n",
    "        # tfa.image.transform_ops.rotate(image, radian) is an alias\n",
    "        image = tfa.image.rotate(image, radian)\n",
    "        # image = tf.image.random_flip_left_right(image)\n",
    "        image = random_translation(image)\n",
    "        return image\n",
    "\n",
    "    # Now, globally set everything to run eagerly\n",
    "    # The following doesn't set to eager mode:\n",
    "    # UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set,\n",
    "    # this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
    "    # tf.config.run_functions_eagerly(True)\n",
    "\n",
    "    # Executing eagerly = False here!\n",
    "    # numpy is only supported in eager mode. If you are in graph mode, it will not be supported.\n",
    "    # In eager execution the shape is always fully-known.\n",
    "    # print('Executing eagerly = {}'.format(tf.executing_eagerly()))\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=3)\n",
    "    # print(type(image), image.shape, image.dtype) # <class 'tensorflow.python.framework.ops.Tensor'> (None, None, 3) <dtype: 'uint8'>\n",
    "\n",
    "    gamma = tf.cast(\n",
    "        parsed[\"image/gamma_index\"],\n",
    "        tf.float32)\n",
    "    # print(type(gamma), gamma.shape, gamma.dtype) # <class 'tensorflow.python.framework.ops.Tensor'> () <dtype: 'float32'>\n",
    "\n",
    "    image = normalization_fn(image)\n",
    "\n",
    "    image = tf.image.resize(image, (img_size, img_size))\n",
    "    print(type(image), image.shape, image.dtype)\n",
    "\n",
    "    if data_augmentation and augment_probability >= random.uniform(0, 1):\n",
    "        gamma_augment = tf.constant(ARG_GAMMA_AUGMENT)\n",
    "        image = tf.cond(tf.math.less(gamma, gamma_augment)\n",
    "                        , lambda: image_augment(image)\n",
    "                        , lambda: image)\n",
    "\n",
    "    # normalizo antes de transformar\n",
    "    # image = normalization_fn(image)\n",
    "    \n",
    "    #label is a tensor of an array of single tf.int64 arrays.\n",
    "    #label = tf.cast(\n",
    "    #    tf.reshape(parsed[\"image/class/label\"], [-1]),\n",
    "    #    tf.int64)\n",
    "\n",
    "    # assert tf.executing_eagerly() FAILS\n",
    "    # parsed[\"image/filename\"] is a Tensor and not an EagerTensor because we are in a map function,\n",
    "    # because in 2.0, code inside Datasets maps is turned into a subgraph for speed, just as it was in 1.x eager\n",
    "    # execution. You generally want to avoid Python inside your data pipeline.\n",
    "    # So, if I invoke parsed[\"image/filename\"].numpy().decode('utf-8') to get the filename string the error\n",
    "    # \"AttributeError: 'Tensor' object has no attribute 'numpy'\" is thrown, hence I return a tensor.\n",
    "    filename = parsed[\"image/filename\"]\n",
    "\n",
    "    if transform_gamma:\n",
    "        gamma = 60.0 - (105 - gamma)\n",
    "        \n",
    "    if standarize_gamma:\n",
    "        gamma = (gamma - train_mean)/train_stdev\n",
    "                    \n",
    "    return image, gamma, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CyTNIMaeyFTX"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 256 # All images will be resized to 256x256\n",
    "if ARG_NETWORK == CNN.mobilenetV2: IMG_SIZE = 224\n",
    "\n",
    "normalization_fn = rescale_0_to_1 # rescale_min_1_to_1\n",
    "# normalization_fn = tf.image.per_image_standardization # loss y mae en validación reportan números muy grandes,\n",
    "# no así en training.\n",
    "\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanAndStdev(raw_train):\n",
    "    train_map = raw_train.map(lambda e: _parse_image_function(e, IMG_SIZE, normalization_fn, ARG_DATA_AUGMENTATION, ARG_AUGMENT_PROBABILITY,\n",
    "                                                      transform_gamma=ARG_TRANSFORM_GAMMA),\n",
    "                      num_parallel_calls=num_workers)\n",
    "    train_gammas = train_map.map(lambda image, gamma, filename: gamma)\n",
    "    train_gammas = np.array(list(train_gammas.as_numpy_iterator())).reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    # los parámetros de la standarización (mean y stdev) se calculan a partir de training\n",
    "    print(scaler.fit(train_gammas))\n",
    "    \n",
    "    # .item() ya que scaler.mean_ es un numpy array\n",
    "    return scaler.mean_.item(), scaler.scale_.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'> (256, 256, 3) <dtype: 'float32'>\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Gammas standarization is enabled, gammas in training: mean=95.67488552913655, stdev=4.68387221943772\n"
     ]
    }
   ],
   "source": [
    "if STANDARIZE_TARGET:\n",
    "    train_mean, train_stdev = getMeanAndStdev(raw_train)\n",
    "    print(f'Gammas standarization is enabled, gammas in training: mean={train_mean}, stdev={train_stdev}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SFZ6ZW7KSXP9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'> (256, 256, 3) <dtype: 'float32'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> (256, 256, 3) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# assert tf.executing_eagerly()\n",
    "if ARG_DATA_AUGMENTATION:\n",
    "    print(\"Training with image augmentation.\")\n",
    "    \n",
    "train = raw_train.map(lambda e: _parse_image_function(e, IMG_SIZE, normalization_fn, ARG_DATA_AUGMENTATION, ARG_AUGMENT_PROBABILITY,\n",
    "                                                      transform_gamma=ARG_TRANSFORM_GAMMA, standarize_gamma=STANDARIZE_TARGET,\n",
    "                                                      train_mean=train_mean, train_stdev=train_stdev),\n",
    "                              num_parallel_calls=num_workers)\n",
    "validation = raw_validation.map(lambda e: _parse_image_function(e, IMG_SIZE, normalization_fn, transform_gamma=ARG_TRANSFORM_GAMMA,\n",
    "                                                                standarize_gamma=STANDARIZE_TARGET, train_mean=train_mean, train_stdev=train_stdev),\n",
    "                                num_parallel_calls=num_workers)\n",
    "if ARG_TEST_PARTITION:\n",
    "    test = raw_test.map(lambda e: _parse_image_function(e, IMG_SIZE, normalization_fn),\n",
    "                        num_parallel_calls=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Yic-I66m6Isv"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = 2 * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "p3UUPdm86LNC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing eagerly = True\n",
      "<PrefetchDataset shapes: ((None, 256, 256, 3), (None,), (None,)), types: (tf.float32, tf.float32, tf.string)>\n",
      "<PrefetchDataset shapes: ((None, 256, 256, 3), (None,), (None,)), types: (tf.float32, tf.float32, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "print('Executing eagerly = {}'.format(tf.executing_eagerly()))\n",
    "\n",
    "# <PrefetchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.int64)>\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER_SIZE)\n",
    "print(train_batches)\n",
    "validation_batches = validation.batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER_SIZE)\n",
    "print(validation_batches)\n",
    "# <BatchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.int64)>\n",
    "if ARG_TEST_PARTITION:\n",
    "    test_batches = test.batch(BATCH_SIZE)\n",
    "    print(test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02rJpcFtChP0"
   },
   "source": [
    "Inspect a batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iknFo3ELBVho"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 256, 256, 3]), TensorShape([32]), TensorShape([32]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch, filename_batch in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "image_batch.shape, label_batch.shape, filename_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5pIy5ehM4YzC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma=0.63, filename=/hdd/data/radioterapia/ciolaplata/2017/1.3.6.1.4.1.9590.100.1.2.211878102012290142122492770690029976478.dcm\n",
      "image shape = (256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display 2nd image in the batch\n",
    "gamma_value = label_batch[8].numpy()\n",
    "filename = filename_batch[8].numpy().decode('utf-8')\n",
    "print(f'gamma={gamma_value:2.2f}, filename={filename}')\n",
    "# if pixel values are float they have to be in [0, 1] range, if they are integer they have to be in the [0, 255] range,\n",
    "# else pixel values are truncated.\n",
    "im = image_batch[8].numpy()\n",
    "plt.imshow(im)\n",
    "print(\"image shape = {}\".format(im.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.62756085>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[:,:,0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkH-kazQecHB"
   },
   "source": [
    "## Create the base model from the pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aiLcQ7JkDM6U"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "if ARG_NETWORK==CNN.resnet18:\n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    base_model = ResNet18(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "    # no transfer learning\n",
    "    # base_model = ResNet18(input_shape=IMG_SHAPE, include_top=False)\n",
    "\n",
    "elif ARG_NETWORK==CNN.resnet34:\n",
    "    ResNet34, preprocess_input = Classifiers.get('resnet34')\n",
    "    base_model = ResNet34(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "elif ARG_NETWORK== CNN.mobilenetV2:\n",
    "    ## Create the base model from the pre-trained model MobileNet V2\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   # alpha=1.4,\n",
    "                                                   weights='imagenet',\n",
    "                                                   include_top=False)\n",
    "\n",
    "else:\n",
    "    base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                                   weights='imagenet',\n",
    "                                                   include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqcsxoJIEVXZ"
   },
   "source": [
    "This feature extractor converts each `160x160x3` image into a `5x5x1280` block of features. See what it does to the example batch of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y-2LJL0EEUcx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlx56nQtfe8Y"
   },
   "source": [
    "## Feature extraction\n",
    "In this step, you will freeze the convolutional base created from the previous step and to use as a feature extractor. Additionally, you add a classifier on top of it and train the top-level classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMLieHBCwil"
   },
   "source": [
    "### Freeze the convolutional base\n",
    "\n",
    "It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. MobileNet V2 has many layers, so setting the entire model's trainable flag to False will freeze all the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OTCJH4bphOeo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_data (BatchNormalization)\n",
      "bn0 (BatchNormalization)\n",
      "stage1_unit1_bn1 (BatchNormalization)\n",
      "stage1_unit1_bn2 (BatchNormalization)\n",
      "stage1_unit2_bn1 (BatchNormalization)\n",
      "stage1_unit2_bn2 (BatchNormalization)\n",
      "stage2_unit1_bn1 (BatchNormalization)\n",
      "stage2_unit1_bn2 (BatchNormalization)\n",
      "stage2_unit2_bn1 (BatchNormalization)\n",
      "stage2_unit2_bn2 (BatchNormalization)\n",
      "stage3_unit1_bn1 (BatchNormalization)\n",
      "stage3_unit1_bn2 (BatchNormalization)\n",
      "stage3_unit2_bn1 (BatchNormalization)\n",
      "stage3_unit2_bn2 (BatchNormalization)\n",
      "stage4_unit1_bn1 (BatchNormalization)\n",
      "stage4_unit1_bn2 (BatchNormalization)\n",
      "stage4_unit2_bn1 (BatchNormalization)\n",
      "stage4_unit2_bn2 (BatchNormalization)\n",
      "bn1 (BatchNormalization)\n"
     ]
    }
   ],
   "source": [
    "if not (ARG_NETWORK == CNN.resnet18 or ARG_NETWORK == CNN.resnet34):\n",
    "    base_model.trainable = False\n",
    "else:\n",
    "    # resnet\n",
    "    for layer in base_model.layers:\n",
    "            if layer.__class__.__name__ != \"BatchNormalization\":\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                print(f\"{layer.name} ({layer.__class__.__name__})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KpbzSmPkDa-N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 11,186,889\n",
      "Trainable params: 7,939\n",
      "Non-trainable params: 11,178,950\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7RFyBW06yFUC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer conv0 has no regularizer.\n",
      "layer stage1_unit1_conv1 has no regularizer.\n",
      "layer stage1_unit1_conv2 has no regularizer.\n",
      "layer stage1_unit1_sc has no regularizer.\n",
      "layer stage1_unit2_conv1 has no regularizer.\n",
      "layer stage1_unit2_conv2 has no regularizer.\n",
      "layer stage2_unit1_conv1 has no regularizer.\n",
      "layer stage2_unit1_conv2 has no regularizer.\n",
      "layer stage2_unit1_sc has no regularizer.\n",
      "layer stage2_unit2_conv1 has no regularizer.\n",
      "layer stage2_unit2_conv2 has no regularizer.\n",
      "layer stage3_unit1_conv1 has no regularizer.\n",
      "layer stage3_unit1_conv2 has no regularizer.\n",
      "layer stage3_unit1_sc has no regularizer.\n",
      "layer stage3_unit2_conv1 has no regularizer.\n",
      "layer stage3_unit2_conv2 has no regularizer.\n",
      "layer stage4_unit1_conv1 has no regularizer.\n",
      "layer stage4_unit1_conv2 has no regularizer.\n",
      "layer stage4_unit1_sc has no regularizer.\n",
      "layer stage4_unit2_conv1 has no regularizer.\n",
      "layer stage4_unit2_conv2 has no regularizer.\n"
     ]
    }
   ],
   "source": [
    "from add_regularization import add_regularization\n",
    "# adds a tf.keras.regularizers.l2(0.0001)\n",
    "#\"kernel_regularizer\":{\n",
    "#                        \"class_name\": \"L1L2\",\n",
    "#                        \"config\": {\n",
    "#                            \"l1\": 0,\n",
    "#                            \"l2\": 0.0001\n",
    "#                        }\n",
    "#                     }\n",
    "if add_regularizers:\n",
    "    base_model = add_regularization(base_model)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    for attr in ['kernel_regularizer']:\n",
    "        if hasattr(layer, attr):\n",
    "            if getattr(layer, attr) is None:\n",
    "                print('layer {} has no regularizer.'.format(layer.name))\n",
    "            else:\n",
    "                print('layer {} has a regularizer {}.'.format(layer.name, getattr(layer, attr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "avX9AnbJyFUH"
   },
   "outputs": [],
   "source": [
    "# display the weights of some layers\n",
    "l = 1\n",
    "for layer in base_model.layers:\n",
    "    # print('layer {:3d}, name: {}'.format(l, layer.name))\n",
    "    if layer.name == \"expanded_conv_project\":\n",
    "        weights = layer.get_weights()\n",
    "        print(layer.get_config(), weights, weights[0].shape)\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dLnpMF5KOALm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzmSozfKDM6W"
   },
   "source": [
    "Stack the feature extractor, and these two layers using a `tf.keras.Sequential` model for network architectures other than ResNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Wv4afXKj6cVa"
   },
   "outputs": [],
   "source": [
    "num_activation_filters = 512\n",
    "if ARG_NETWORK == CNN.mobilenetV2:\n",
    "    num_activation_filters = 1280\n",
    "\n",
    "if not (ARG_NETWORK == CNN.resnet18 or ARG_NETWORK == CNN.resnet34):\n",
    "    # Pablo March 10: add sigmoid\n",
    "    # WARNING: adding the activation function causes loss to keep close to 0.5 and does not decrease.\n",
    "    # prediction_layer = keras.layers.Dense(1, activation='sigmoid') # para obtener probabilidades y no logits\n",
    "\n",
    "    # https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes\n",
    "    # https://stackoverflow.com/questions/58627411/how-to-use-inception-network-for-regression\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    fc1 = keras.layers.Dense(num_activation_filters, activation='relu')\n",
    "    #fc2 = keras.layers.Dense(num_activation_filders, activation='relu')\n",
    "    #dropout = keras.layers.Dropout(rate=0.05) # no funciona\n",
    "    # and a linear output layer (regression)\n",
    "\n",
    "    bn = keras.layers.BatchNormalization() # same as ResNet18 but with VGG16 is worst.\n",
    "\n",
    "    prediction_layer = keras.layers.Dense(1, activation='linear')\n",
    "    # and a logistic layer -- let's say we have 200 classes (classification)\n",
    "    # prediction_layer = Dense(200, activation='softmax')(x)\n",
    "\n",
    "    # Up to March 27, 2020\n",
    "    # prediction_layer = keras.layers.Dense(1)\n",
    "    prediction_batch = prediction_layer(feature_batch_average)\n",
    "    print(prediction_batch.shape)\n",
    "\n",
    "    # Now stack the feature extractor, and these two layers using a `tf.keras.Sequential` model:\n",
    "    model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      fc1,\n",
    "      #bn,\n",
    "      #dropout,\n",
    "      #fc2,\n",
    "      prediction_layer\n",
    "    ])\n",
    "    \n",
    "else:\n",
    "    avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    out = tf.keras.layers.Dense(num_activation_filters, activation=\"relu\")(avg) # CHANGE to use avg pool only or avg pool + max pool\n",
    "    if ARG_RESNET_USE_BN:\n",
    "        # no observé mejoras en 2017 agregando esta bn layer, pero sí observé mejoras en 4 de 5 folds de cross validation\n",
    "        # en 2019+2017\n",
    "        out = tf.keras.layers.BatchNormalization()(out)\n",
    "    prediction_layer = tf.keras.layers.Dense(1, activation='linear')(out)\n",
    "    model = keras.models.Model(inputs=base_model.input, outputs=prediction_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0ylJXE_kRLi"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "You must compile the model before training it.  Since there are two classes, use a binary cross-entropy loss with `from_logits=True` since the model provides a linear output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RpR8HdyMhukJ"
   },
   "outputs": [],
   "source": [
    "# mse = square(y_true - y_pred)\n",
    "# mae = loss = abs(y_true - y_pred)\n",
    "# mape = 100 * abs(y_true - y_pred) / y_true\n",
    "# mae y mape son similares, no iguales, por eso tomo MAE que es el promedio de la diferencia absoluta entre el\n",
    "# gamma real y el gamma predicho\n",
    "# optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate, momentum=0.95)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "I8ARiyMFsgbH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 11,452,106\n",
      "Trainable params: 272,132\n",
      "Non-trainable params: 11,179,974\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxvgOYTDSWTx"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hlHEavK7DUI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in train partition: 3414, in validation: 854.\n"
     ]
    }
   ],
   "source": [
    "num_train = sum(1 for _ in raw_train)\n",
    "num_val = sum(1 for _ in raw_validation)\n",
    "print(f'Number of images in train partition: {num_train}, in validation: {num_val}.')\n",
    "if ARG_TEST_PARTITION:\n",
    "    num_test = sum(1 for _ in raw_test)\n",
    "    print(f'Number of images in test partiton: {num_test}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Om4O3EESkab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
    "validation_steps=20\n",
    "\n",
    "# projects out just the first two components.\n",
    "tmp_validation_batches = validation_batches.map(lambda image, gamma, filename: (image, gamma))\n",
    "print(tmp_validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8cYT1c48CuSd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 31ms/step - loss: 1.0372 - mse: 1.3816\n",
      "initial loss: 1.04\n",
      "initial mape: 1.38\n"
     ]
    }
   ],
   "source": [
    "loss0 = mse0 = 0\n",
    "loss0, mse0 = model.evaluate(tmp_validation_batches, steps = validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial mape: {:.2f}\".format(mse0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JsaRFlZ9B6WK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "# projects out just the first two components.\n",
    "tmp_train_batches = train_batches.map(lambda image, gamma, filename: (image, gamma))\n",
    "print(tmp_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "XTtp6LG7yFUw"
   },
   "outputs": [],
   "source": [
    "# Implement callback function to stop training\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, wait_epochs):\n",
    "        self.__wait_epochs = wait_epochs\n",
    "        self.__latest_peak_mae = 50.0 # MobileNetV2 requires such a high value because it improves very slowly.\n",
    "        self.__waited_epochs = 0\n",
    "        self.__saved_model_file = None\n",
    "        self.__saved_model = None\n",
    "        \n",
    "    def stopTraining(self, epoch, val_mae):\n",
    "        stop_early = False\n",
    "        best_mae = False\n",
    "        # check for early stop\n",
    "        if val_mae < self.__latest_peak_mae and abs(val_mae - self.__latest_peak_mae) > ARG_MIN_DELTA_MAE:\n",
    "            best_mae = True\n",
    "            self.__latest_peak_mae = val_mae\n",
    "            print(f\"\\nNew peak val_mae reached: {val_mae:6.3}\")\n",
    "\n",
    "            t = time.time()\n",
    "            dir = os.path.join(ARG_DATASET_DIR, \"models\")\n",
    "            save_model_path = \"{}/{}.{}.{}.h5\".format(dir, int(t), ARG_NETWORK.name, ARG_RANDOM_SEED)\n",
    "            print(save_model_path)\n",
    "            # Either 'tf' or 'h5', indicating whether to save the model to Tensorflow SavedModel or HDF5. Defaults to 'tf' \n",
    "            # in TF 2.X, and 'h5' in TF 1.X.            \n",
    "            model.save(save_model_path, save_format='h5')\n",
    "            # borro el archivo del modelo anterior\n",
    "            if self.__saved_model_file is not None:\n",
    "                os.remove(self.__saved_model_file)\n",
    "            self.__saved_model_file = save_model_path\n",
    "            reloaded_model = tf.keras.models.load_model(save_model_path)\n",
    "            self.__saved_model = reloaded_model\n",
    "\n",
    "        if val_mae > self.__latest_peak_mae or not best_mae:\n",
    "            # Si llevo N+ epochs sin mejora\n",
    "            if self.__waited_epochs >= self.__wait_epochs:\n",
    "                print(\"\\nStopping early at epoch {0} with saved peak mae {1:10.8}\"\n",
    "                      .format(epoch + 1, self.__latest_peak_mae))\n",
    "                stop_early = True\n",
    "            \n",
    "            self.__waited_epochs += 1\n",
    "            \n",
    "        else:\n",
    "            self.__latest_peak_mae = val_mae\n",
    "            # Reset waited epochs.\n",
    "            print(\"waiting epochs reset.\")\n",
    "            self.reset_waited_epochs()\n",
    "            \n",
    "        return stop_early\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # print('\\nTraining: epoch {} ends at {}'.format(epoch, datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "        if self.stopTraining(epoch, logs.get('val_loss')):\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    @property\n",
    "    def saved_model_file(self):\n",
    "        return self.__saved_model_file\n",
    "    \n",
    "    @property\n",
    "    def saved_model(self):\n",
    "        return self.__saved_model\n",
    "\n",
    "    def reset_waited_epochs(self):\n",
    "        self.__waited_epochs = 0;\n",
    "    \n",
    "\n",
    "# Instantiate a callback object\n",
    "callbackObj = MyCallback(ARG_EPOCHS_WO_IMPROVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MZyPn887yFUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 0.8955 - mse: 1.4381 - val_loss: 1.0968 - val_mse: 1.5053\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.6110 - mse: 0.7206 - val_loss: 0.8999 - val_mse: 1.1579\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.5295 - mse: 0.6057 - val_loss: 1.9463 - val_mse: 4.2095\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.4833 - mse: 0.5279 - val_loss: 1.6415 - val_mse: 3.0687\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.4653 - mse: 0.5056 - val_loss: 1.5673 - val_mse: 2.8554\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.4413 - mse: 0.4569 - val_loss: 1.6161 - val_mse: 3.2686\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 0.4242 - mse: 0.4300 - val_loss: 2.7458 - val_mse: 8.2923\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.4156 - mse: 0.4089 - val_loss: 1.5845 - val_mse: 2.9637\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.4036 - mse: 0.4066 - val_loss: 2.0435 - val_mse: 4.7502\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.3983 - mse: 0.3733 - val_loss: 3.1794 - val_mse: 10.8446\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tmp_train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=tmp_validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd94CKImf8vi"
   },
   "source": [
    "### Learning curves\n",
    "\n",
    "Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNet V2 base model as a fixed feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "zvmYWOgoyFU4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4Po3M6UrGvKr"
   },
   "outputs": [],
   "source": [
    "# Pablo Feb 25:\n",
    "# Python never implicitly copies objects. When you set list2 = list1, you are making them refer to the same exact\n",
    "# list object, so when you mutate it, all references to it keep referring to the object in its current state.\n",
    "mse = history.history['mse'].copy()\n",
    "val_mse = history.history['val_mse'].copy()\n",
    "\n",
    "loss = history.history['loss'].copy()\n",
    "val_loss = history.history['val_loss'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "53OTCh3jnbwV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(mse, label='Training MSE')\n",
    "plt.plot(val_mse, label='Validation MSE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim([0,50])\n",
    "plt.title('Training and Validation MSE')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0,10])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqwV-CRdS6Nv"
   },
   "source": [
    "## Fine tuning\n",
    "In the feature extraction experiment, you were only training a few layers on top of a VGG16 base model. The weights of the pre-trained network were **not** updated during training.\n",
    "\n",
    "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n",
    "\n",
    "Note: This should only be attempted after you have trained the top-level classifier with the pre-trained model set to non-trainable. If you add a randomly initialized classifier on top of a pre-trained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) and your pre-trained model will forget what it has learned.\n",
    "\n",
    "Also, you should try to fine-tune a small number of top layers rather than the whole VGG16 model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPXnzUK0QonF"
   },
   "source": [
    "### Un-freeze the top layers of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfxv_ifotQak"
   },
   "source": [
    "All you need to do is unfreeze the `base_model` and set the bottom layers to be un-trainable. Then, you should recompile the model (necessary for these changes to take effect), and resume training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4nzcagVitLQm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer   1, name: data\n",
      "layer   2, name: bn_data\n",
      "layer   3, name: zero_padding2d\n",
      "layer   4, name: conv0\n",
      "layer   5, name: bn0\n",
      "layer   6, name: relu0\n",
      "layer   7, name: zero_padding2d_1\n",
      "layer   8, name: pooling0\n",
      "layer   9, name: stage1_unit1_bn1\n",
      "layer  10, name: stage1_unit1_relu1\n",
      "layer  11, name: zero_padding2d_2\n",
      "layer  12, name: stage1_unit1_conv1\n",
      "layer  13, name: stage1_unit1_bn2\n",
      "layer  14, name: stage1_unit1_relu2\n",
      "layer  15, name: zero_padding2d_3\n",
      "layer  16, name: stage1_unit1_conv2\n",
      "layer  17, name: stage1_unit1_sc\n",
      "layer  18, name: add\n",
      "layer  19, name: stage1_unit2_bn1\n",
      "layer  20, name: stage1_unit2_relu1\n",
      "layer  21, name: zero_padding2d_4\n",
      "layer  22, name: stage1_unit2_conv1\n",
      "layer  23, name: stage1_unit2_bn2\n",
      "layer  24, name: stage1_unit2_relu2\n",
      "layer  25, name: zero_padding2d_5\n",
      "layer  26, name: stage1_unit2_conv2\n",
      "layer  27, name: add_1\n",
      "layer  28, name: stage2_unit1_bn1\n",
      "layer  29, name: stage2_unit1_relu1\n",
      "layer  30, name: zero_padding2d_6\n",
      "layer  31, name: stage2_unit1_conv1\n",
      "layer  32, name: stage2_unit1_bn2\n",
      "layer  33, name: stage2_unit1_relu2\n",
      "layer  34, name: zero_padding2d_7\n",
      "layer  35, name: stage2_unit1_conv2\n",
      "layer  36, name: stage2_unit1_sc\n",
      "layer  37, name: add_2\n",
      "layer  38, name: stage2_unit2_bn1\n",
      "layer  39, name: stage2_unit2_relu1\n",
      "layer  40, name: zero_padding2d_8\n",
      "layer  41, name: stage2_unit2_conv1\n",
      "layer  42, name: stage2_unit2_bn2\n",
      "layer  43, name: stage2_unit2_relu2\n",
      "layer  44, name: zero_padding2d_9\n",
      "layer  45, name: stage2_unit2_conv2\n",
      "layer  46, name: add_3\n",
      "layer  47, name: stage3_unit1_bn1\n",
      "layer  48, name: stage3_unit1_relu1\n",
      "layer  49, name: zero_padding2d_10\n",
      "layer  50, name: stage3_unit1_conv1\n",
      "layer  51, name: stage3_unit1_bn2\n",
      "layer  52, name: stage3_unit1_relu2\n",
      "layer  53, name: zero_padding2d_11\n",
      "layer  54, name: stage3_unit1_conv2\n",
      "layer  55, name: stage3_unit1_sc\n",
      "layer  56, name: add_4\n",
      "layer  57, name: stage3_unit2_bn1\n",
      "layer  58, name: stage3_unit2_relu1\n",
      "layer  59, name: zero_padding2d_12\n",
      "layer  60, name: stage3_unit2_conv1\n",
      "layer  61, name: stage3_unit2_bn2\n",
      "layer  62, name: stage3_unit2_relu2\n",
      "layer  63, name: zero_padding2d_13\n",
      "layer  64, name: stage3_unit2_conv2\n",
      "layer  65, name: add_5\n",
      "layer  66, name: stage4_unit1_bn1\n",
      "layer  67, name: stage4_unit1_relu1\n",
      "layer  68, name: zero_padding2d_14\n",
      "layer  69, name: stage4_unit1_conv1\n",
      "layer  70, name: stage4_unit1_bn2\n",
      "layer  71, name: stage4_unit1_relu2\n",
      "layer  72, name: zero_padding2d_15\n",
      "layer  73, name: stage4_unit1_conv2\n",
      "layer  74, name: stage4_unit1_sc\n",
      "layer  75, name: add_6\n",
      "layer  76, name: stage4_unit2_bn1\n",
      "layer  77, name: stage4_unit2_relu1\n",
      "layer  78, name: zero_padding2d_16\n",
      "layer  79, name: stage4_unit2_conv1\n",
      "layer  80, name: stage4_unit2_bn2\n",
      "layer  81, name: stage4_unit2_relu2\n",
      "layer  82, name: zero_padding2d_17\n",
      "layer  83, name: stage4_unit2_conv2\n",
      "layer  84, name: add_7\n",
      "layer  85, name: bn1\n",
      "layer  86, name: relu1\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Pablo Feb 25: con este loop me aseguro que las capas que en la próxima celda *NO* pongo como layer.trainable = False sean\n",
    "# trainable.\n",
    "l = 1\n",
    "for layer in base_model.layers:\n",
    "    print('layer {:3d}, name: {}'.format(l, layer.name))\n",
    "    if layer.__class__.__name__ != \"BatchNormalization\":\n",
    "        layer.trainable =  True\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "-4HgVAacRs5v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  86\n",
      "layer   1, name: data set to not trainable.\n",
      "layer   3, name: zero_padding2d set to not trainable.\n",
      "layer   4, name: conv0 set to not trainable.\n",
      "layer   6, name: relu0 set to not trainable.\n",
      "layer   7, name: zero_padding2d_1 set to not trainable.\n",
      "layer   8, name: pooling0 set to not trainable.\n",
      "layer  10, name: stage1_unit1_relu1 set to not trainable.\n",
      "layer  11, name: zero_padding2d_2 set to not trainable.\n",
      "layer  12, name: stage1_unit1_conv1 set to not trainable.\n",
      "layer  14, name: stage1_unit1_relu2 set to not trainable.\n",
      "layer  15, name: zero_padding2d_3 set to not trainable.\n",
      "layer  16, name: stage1_unit1_conv2 set to not trainable.\n",
      "layer  17, name: stage1_unit1_sc set to not trainable.\n",
      "layer  18, name: add set to not trainable.\n",
      "layer  20, name: stage1_unit2_relu1 set to not trainable.\n",
      "layer  21, name: zero_padding2d_4 set to not trainable.\n",
      "layer  22, name: stage1_unit2_conv1 set to not trainable.\n",
      "layer  24, name: stage1_unit2_relu2 set to not trainable.\n",
      "layer  25, name: zero_padding2d_5 set to not trainable.\n",
      "layer  26, name: stage1_unit2_conv2 set to not trainable.\n",
      "layer  27, name: add_1 set to not trainable.\n",
      "layer  29, name: stage2_unit1_relu1 set to not trainable.\n",
      "layer  30, name: zero_padding2d_6 set to not trainable.\n",
      "layer  31, name: stage2_unit1_conv1 set to not trainable.\n",
      "layer  33, name: stage2_unit1_relu2 set to not trainable.\n",
      "layer  34, name: zero_padding2d_7 set to not trainable.\n",
      "layer  35, name: stage2_unit1_conv2 set to not trainable.\n",
      "layer  36, name: stage2_unit1_sc set to not trainable.\n",
      "layer  37, name: add_2 set to not trainable.\n",
      "layer  39, name: stage2_unit2_relu1 set to not trainable.\n",
      "layer  40, name: zero_padding2d_8 set to not trainable.\n",
      "layer  41, name: stage2_unit2_conv1 set to not trainable.\n",
      "layer  43, name: stage2_unit2_relu2 set to not trainable.\n",
      "layer  44, name: zero_padding2d_9 set to not trainable.\n",
      "layer  45, name: stage2_unit2_conv2 set to not trainable.\n",
      "layer  46, name: add_3 set to not trainable.\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "l = 1\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    if layer.__class__.__name__ != \"BatchNormalization\":\n",
    "        print('layer {:3d}, name: {} set to not trainable.'.format(l, layer.name))\n",
    "        layer.trainable = False\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Uk1dgsxT0IS"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "Compile the model using a much lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "AVvlrXb9yFVH"
   },
   "outputs": [],
   "source": [
    "# This function keeps the learning rate at 0.001 for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def lr_scheduler(epoch):\n",
    "    lr = base_learning_rate\n",
    "    #k = 0.15\n",
    "    #if epoch >= 10 and epoch <= 40:\n",
    "    #    lr = tf.math.exp(k * (10 - epoch)) * base_learning_rate\n",
    "    #    print(\"\\nlearning rate: %.8f\"%(lr))\n",
    "    if epoch >= 10 and epoch <= 30:\n",
    "        lr = base_learning_rate/10\n",
    "    elif epoch > 30 and epoch <= 60:\n",
    "        lr = base_learning_rate/100\n",
    "    elif epoch > 60:\n",
    "        lr = base_learning_rate/500\n",
    "    print(\"\\nlearning rate: %.6f\"%(lr))\n",
    "    \n",
    "    return lr\n",
    "    \n",
    "    \n",
    "callbackLR = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "MvJPcR-PIEu2"
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=ARG_LR_PATIENCE, verbose=1, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "NtUnaz0WUDva"
   },
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10, momentum=0.95)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/10, epsilon=1e-08, amsgrad=False)\n",
    "model.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              optimizer = optimizer,\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "WwBWy7J2kZvA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 11,452,106\n",
      "Trainable params: 10,757,892\n",
      "Non-trainable params: 694,214\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bNXelbMQtonr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5O4jd6TuAG"
   },
   "source": [
    "### Continue training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0foWUN-yDLo_"
   },
   "source": [
    "If you trained to convergence earlier, this step will improve your accuracy by a few percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ECQLkAsFTlun"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/210\n",
      "    107/Unknown - 8s 76ms/step - loss: 0.4216 - mse: 0.4356\n",
      "New peak val_mae reached:   1.26\n",
      "/hdd/data/radioterapia/ciolaplata/models/1614476027.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "107/107 [==============================] - 10s 94ms/step - loss: 0.4216 - mse: 0.4356 - val_loss: 1.2573 - val_mse: 2.3197 - lr: 1.0000e-04\n",
      "Epoch 12/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3528 - mse: 0.3219\n",
      "New peak val_mae reached:  0.546\n",
      "/hdd/data/radioterapia/ciolaplata/models/1614476037.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "107/107 [==============================] - 10s 92ms/step - loss: 0.3528 - mse: 0.3219 - val_loss: 0.5462 - val_mse: 0.6030 - lr: 1.0000e-04\n",
      "Epoch 13/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3289 - mse: 0.2765\n",
      "New peak val_mae reached:   0.39\n",
      "/hdd/data/radioterapia/ciolaplata/models/1614476047.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.3289 - mse: 0.2765 - val_loss: 0.3897 - val_mse: 0.4109 - lr: 1.0000e-04\n",
      "Epoch 14/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2967 - mse: 0.2226 - val_loss: 0.4235 - val_mse: 0.4303 - lr: 1.0000e-04\n",
      "Epoch 15/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2778 - mse: 0.1961 - val_loss: 0.4317 - val_mse: 0.4172 - lr: 1.0000e-04\n",
      "Epoch 16/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2642 - mse: 0.1765 - val_loss: 0.4150 - val_mse: 0.4355 - lr: 1.0000e-04\n",
      "Epoch 17/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2644 - mse: 0.1750\n",
      "New peak val_mae reached:  0.378\n",
      "/hdd/data/radioterapia/ciolaplata/models/1614476084.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.2644 - mse: 0.1750 - val_loss: 0.3781 - val_mse: 0.3722 - lr: 1.0000e-04\n",
      "Epoch 18/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2537 - mse: 0.1643 - val_loss: 0.3913 - val_mse: 0.3690 - lr: 1.0000e-04\n",
      "Epoch 19/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2270 - mse: 0.1313 - val_loss: 0.3995 - val_mse: 0.4097 - lr: 1.0000e-04\n",
      "Epoch 20/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2312 - mse: 0.1346 - val_loss: 0.3717 - val_mse: 0.3781 - lr: 1.0000e-04\n",
      "Epoch 21/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2186 - mse: 0.1177 - val_loss: 0.3771 - val_mse: 0.3805 - lr: 1.0000e-04\n",
      "Epoch 22/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2173 - mse: 0.1241 - val_loss: 0.3972 - val_mse: 0.4176 - lr: 1.0000e-04\n",
      "Epoch 23/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2173 - mse: 0.1182 - val_loss: 0.3749 - val_mse: 0.3764 - lr: 1.0000e-04\n",
      "Epoch 24/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2119 - mse: 0.1079 - val_loss: 0.3901 - val_mse: 0.3600 - lr: 1.0000e-04\n",
      "Epoch 25/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2181 - mse: 0.1179 - val_loss: 0.3755 - val_mse: 0.3788 - lr: 1.0000e-04\n",
      "Epoch 26/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2017 - mse: 0.1009 - val_loss: 0.3701 - val_mse: 0.3579 - lr: 1.0000e-04\n",
      "Epoch 27/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2011 - mse: 0.0974\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.2011 - mse: 0.0974 - val_loss: 0.4078 - val_mse: 0.3737 - lr: 1.0000e-04\n",
      "Epoch 28/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1846 - mse: 0.0884 - val_loss: 0.3694 - val_mse: 0.3535 - lr: 2.0000e-05\n",
      "Epoch 29/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1929 - mse: 0.0970 - val_loss: 0.3684 - val_mse: 0.3434 - lr: 2.0000e-05\n",
      "Epoch 30/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.1612 - mse: 0.0688\n",
      "New peak val_mae reached:  0.358\n",
      "/hdd/data/radioterapia/ciolaplata/models/1614476203.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "107/107 [==============================] - 10s 90ms/step - loss: 0.1612 - mse: 0.0688 - val_loss: 0.3577 - val_mse: 0.3453 - lr: 2.0000e-05\n",
      "Epoch 31/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1637 - mse: 0.0704 - val_loss: 0.3600 - val_mse: 0.3409 - lr: 2.0000e-05\n",
      "Epoch 32/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1595 - mse: 0.0642 - val_loss: 0.3634 - val_mse: 0.3397 - lr: 2.0000e-05\n",
      "Epoch 33/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1710 - mse: 0.0724 - val_loss: 0.3629 - val_mse: 0.3431 - lr: 2.0000e-05\n",
      "Epoch 34/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1623 - mse: 0.0660 - val_loss: 0.3668 - val_mse: 0.3413 - lr: 2.0000e-05\n",
      "Epoch 35/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1637 - mse: 0.0620 - val_loss: 0.3586 - val_mse: 0.3409 - lr: 2.0000e-05\n",
      "Epoch 36/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1711 - mse: 0.0699 - val_loss: 0.3673 - val_mse: 0.3473 - lr: 2.0000e-05\n",
      "Epoch 37/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1458 - mse: 0.0541 - val_loss: 0.3655 - val_mse: 0.3450 - lr: 2.0000e-05\n",
      "Epoch 38/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1704 - mse: 0.0732 - val_loss: 0.3616 - val_mse: 0.3442 - lr: 2.0000e-05\n",
      "Epoch 39/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1534 - mse: 0.0578 - val_loss: 0.3660 - val_mse: 0.3392 - lr: 2.0000e-05\n",
      "Epoch 40/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.1676 - mse: 0.0658\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1676 - mse: 0.0658 - val_loss: 0.3661 - val_mse: 0.3433 - lr: 2.0000e-05\n",
      "Epoch 41/210\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.1509 - mse: 0.0540 - val_loss: 0.3615 - val_mse: 0.3434 - lr: 4.0000e-06\n",
      "Epoch 42/210\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.1531 - mse: 0.0530 - val_loss: 0.3627 - val_mse: 0.3394 - lr: 4.0000e-06\n",
      "Epoch 43/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1499 - mse: 0.0508 - val_loss: 0.3626 - val_mse: 0.3393 - lr: 4.0000e-06\n",
      "Epoch 44/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1580 - mse: 0.0593 - val_loss: 0.3631 - val_mse: 0.3424 - lr: 4.0000e-06\n",
      "Epoch 45/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1507 - mse: 0.0522 - val_loss: 0.3633 - val_mse: 0.3410 - lr: 4.0000e-06\n",
      "Epoch 46/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1370 - mse: 0.0439 - val_loss: 0.3617 - val_mse: 0.3418 - lr: 4.0000e-06\n",
      "Epoch 47/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1491 - mse: 0.0518 - val_loss: 0.3639 - val_mse: 0.3421 - lr: 4.0000e-06\n",
      "Epoch 48/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1442 - mse: 0.0479 - val_loss: 0.3628 - val_mse: 0.3392 - lr: 4.0000e-06\n",
      "Epoch 49/210\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1606 - mse: 0.0596 - val_loss: 0.3631 - val_mse: 0.3425 - lr: 4.0000e-06\n",
      "Epoch 50/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.1614 - mse: 0.0576\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1614 - mse: 0.0576 - val_loss: 0.3643 - val_mse: 0.3410 - lr: 4.0000e-06\n",
      "Epoch 51/210\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.1476 - mse: 0.0521\n",
      "Stopping early at epoch 51 with saved peak mae 0.35770908\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.1476 - mse: 0.0521 - val_loss: 0.3640 - val_mse: 0.3394 - lr: 8.0000e-07\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = ARG_MAX_FINE_TUNING_EPOCHS\n",
    "try:\n",
    "    history.epoch\n",
    "except NameError:\n",
    "    total_epochs = fine_tune_epochs\n",
    "    initial_epoch =  0\n",
    "else:\n",
    "    total_epochs =  (history.epoch[-1]+1) + fine_tune_epochs\n",
    "    initial_epoch =  history.epoch[-1]+1\n",
    "\n",
    "# by default we use custom LR schedule\n",
    "callbacks=[callbackObj, callbackLR]\n",
    "if ARG_LR_SCHEDULE == 1:\n",
    "    callbacks=[callbackObj, reduce_lr]\n",
    "    \n",
    "history_fine = model.fit(tmp_train_batches,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch =  initial_epoch,\n",
    "                         validation_data=tmp_validation_batches,\n",
    "                         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "vjiNEG47yFVY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n"
     ]
    }
   ],
   "source": [
    "print(history_fine.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.31970477104187,\n",
       " 0.6029694080352783,\n",
       " 0.4108881652355194,\n",
       " 0.43026143312454224,\n",
       " 0.41716882586479187,\n",
       " 0.4355281889438629,\n",
       " 0.3721557855606079,\n",
       " 0.36902880668640137,\n",
       " 0.4097331464290619,\n",
       " 0.37805289030075073,\n",
       " 0.38054126501083374,\n",
       " 0.41758963465690613,\n",
       " 0.3764341175556183,\n",
       " 0.3600442409515381,\n",
       " 0.37878915667533875,\n",
       " 0.35793811082839966,\n",
       " 0.3736896514892578,\n",
       " 0.3534805476665497,\n",
       " 0.34343332052230835,\n",
       " 0.3453004062175751,\n",
       " 0.3408721387386322,\n",
       " 0.33969756960868835,\n",
       " 0.34306323528289795,\n",
       " 0.341310977935791,\n",
       " 0.3409014940261841,\n",
       " 0.34725630283355713,\n",
       " 0.34501779079437256,\n",
       " 0.3442099690437317,\n",
       " 0.3392205238342285,\n",
       " 0.3433260917663574,\n",
       " 0.3433871567249298,\n",
       " 0.339448481798172,\n",
       " 0.3392772674560547,\n",
       " 0.3423658013343811,\n",
       " 0.3410458564758301,\n",
       " 0.3418010473251343,\n",
       " 0.3421345353126526,\n",
       " 0.3392345905303955,\n",
       " 0.3425005078315735,\n",
       " 0.34096789360046387,\n",
       " 0.3394438624382019]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_fine.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "PpA8PlpQKygw"
   },
   "outputs": [],
   "source": [
    "mse += history_fine.history['mse']\n",
    "val_mse += history_fine.history['val_mse']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Igm8aMrLyFVj"
   },
   "outputs": [],
   "source": [
    "mse = mse[1:]\n",
    "val_mse = val_mse[1:]\n",
    "loss = loss[1:]\n",
    "val_loss = val_loss[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "chW103JUItdk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(mse, label='Training MSE')\n",
    "plt.plot(val_mse, label='Validation MSE')\n",
    "plt.ylim([0, 30])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Fine Tuning starts')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 5])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Fine Tuning Starts')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TZTwG7nhm0C"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "* **Using a pre-trained model for feature extraction**:  When working with a small dataset, it is a common practice to take advantage of features learned by a model trained on a larger dataset in the same domain. This is done by instantiating the pre-trained model and adding a fully-connected classifier on top. The pre-trained model is \"frozen\" and only the weights of the classifier get updated during training.\n",
    "In this case, the convolutional base extracted all the features associated with each image and you just trained a classifier that determines the image class given that set of extracted features.\n",
    "\n",
    "* **Fine-tuning a pre-trained model**: To further improve performance, one might want to repurpose the top-level layers of the pre-trained models to the new dataset via fine-tuning.\n",
    "In this case, you tuned your weights such that your model learned high-level features specific to the dataset. This technique is usually recommended when the training dataset is large and very similar to the original dataset that the pre-trained model was trained on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "eQy9mVkuoFWj"
   },
   "outputs": [],
   "source": [
    "if isGoogleColab():\n",
    "    !ls -l \"/content/drive/MyDrive/Healthcare/Radioterapia/data/ciolaplata/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "f4tr0VXGyFVr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best saved model file = /hdd/data/radioterapia/ciolaplata/models/1614476203.resnet18.23456.h5\n"
     ]
    }
   ],
   "source": [
    "print(f'Best saved model file = {callbackObj.saved_model_file}')\n",
    "saved_model = callbackObj.saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "esaw0xjhyFVv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 - 3s - loss: 0.0876 - mean_squared_error: 0.0199\n",
      "Saved model, train loss: 0.0876\n",
      "Saved model, train mse: 0.0199\n",
      "\n",
      "27/27 - 1s - loss: 0.3577 - mean_squared_error: 0.3453\n",
      "Saved model, validation loss: 0.3577\n",
      "Saved model, validation mse: 0.3453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the saved model on the train set which differs from values reported during training\n",
    "loss, mse = saved_model.evaluate(tmp_train_batches, verbose=2)\n",
    "print(\"Saved model, train loss: {:5.4f}\".format(loss))\n",
    "print('Saved model, train mse: {:5.4f}\\n'.format(mse))\n",
    "\n",
    "# Evaluate the saved model on the validation set which differs from values reported during training\n",
    "loss, mse = saved_model.evaluate(tmp_validation_batches, verbose=2)\n",
    "print(\"Saved model, validation loss: {:5.4f}\".format(loss))\n",
    "print('Saved model, validation mse: {:5.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "qACCSCEAyFVz"
   },
   "outputs": [],
   "source": [
    "#result_batch = model.predict(tmp_train_batches)\n",
    "#reloaded_result_batch = reloaded_model.predict(tmp_train_batches)\n",
    "#print(abs(reloaded_result_batch - result_batch).max())\n",
    "#np.testing.assert_allclose(result_batch, reloaded_result_batch, rtol=1e-6, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "kcEpqDWFyFV4"
   },
   "outputs": [],
   "source": [
    "# projects out just the first two components.\n",
    "if ARG_TEST_PARTITION:\n",
    "    tmp_test_batches = test_batches.map(lambda image, gamma, filename: (image, gamma))\n",
    "    print(tmp_test_batches)\n",
    "\n",
    "    # Evaluate the reloaded model on the test set\n",
    "    loss, mse = saved_model.evaluate(tmp_test_batches, verbose=1)\n",
    "    print(\"\\n\\nSaved model, test loss: {:5.4f}\".format(loss))\n",
    "    print('Saved model, test mse: {:5.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "R1oRiBayRPVt"
   },
   "outputs": [],
   "source": [
    "if isGoogleColab():\n",
    "    drive.flush_and_unmount()\n",
    "    print('All changes made in this colab session should now be visible in Drive.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "transfer_learning.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
