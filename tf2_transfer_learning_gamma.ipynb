{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pablojrios/fluence_maps/blob/master/tf2_transfer_learning_gamma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRTa3Ee15WsJ"
   },
   "source": [
    "# Transfer learning with a pretrained ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wRK8ctZQIEuc"
   },
   "outputs": [],
   "source": [
    "def isGoogleColab():\n",
    "    # 'ipykernel.zmqshell' runs in our server\n",
    "    # 'google.colab._shell' runs in Google Colab\n",
    "    return get_ipython().__class__.__module__ == 'google.colab._shell'\n",
    "\n",
    "#import sys\n",
    "#import IPython\n",
    "\n",
    "#if 'ipykernel' in sys.modules:\n",
    "#    ip = sys.modules['ipykernel']\n",
    "#    ip_version = ip.version_info\n",
    "#    ip_client = ip.write_connection_file.__module__.split('.')[0]\n",
    "\n",
    "#ip_version, ip_client\n",
    "\n",
    "#ip_version = IPython.utils.sysinfo.get_sys_info()['ipython_version']\n",
    "#ip_version\n",
    "\n",
    "#if 'IPython' in sys.modules:\n",
    "#    ip = sys.modules['IPython']\n",
    "#    ip_version = ip.version_info\n",
    "#    print(ip_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iBMcobPHdD8O"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "from random import shuffle, randrange\n",
    "import random\n",
    "import tensorflow_addons as tfa\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version = 2.2.0, addons version = 0.10.0\n",
      "Executing eagerly = True\n",
      "OpenCV version = 3.4.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'12/02/2021 15:00:32'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow version = {}, addons version = {}'.format(tf.__version__, tfa.__version__))\n",
    "print('Executing eagerly = {}'.format(tf.executing_eagerly()))\n",
    "keras = tf.keras\n",
    "\n",
    "import cv2 # to perform data augmentation\n",
    "print('OpenCV version = {}'.format(cv2.__version__))\n",
    "\n",
    "datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q50x39yF5BPt"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "if isGoogleColab():\n",
    "    %cd '/content'\n",
    "    if os.path.exists('fluence_maps'):\n",
    "      !rm -fr fluence_maps\n",
    "\n",
    "    ## Install required dependencies\n",
    "    !pip install -q pydicom\n",
    "    ## to support ResNet18 and ResNet34\n",
    "    !pip install image-classifiers\n",
    "    ## https://github.com/tensorflow/addons/issues/2251\n",
    "    !pip install -U tensorflow-addons\n",
    "\n",
    "    GIT_USERNAME = \"pablojrios\"\n",
    "    GIT_TOKEN = \"1d88a0b85d2b00a03796e4d8b7e5f7b249b12f9b\"\n",
    "    !git clone -s https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/fluence_maps.git\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    %cd -q '/content/fluence_maps'\n",
    "    \n",
    "    ARG_DATASET_DIR='/content/drive/My Drive/Healthcare/Radioterapia/data/ciolaplata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LhWAVjltIJWh"
   },
   "outputs": [],
   "source": [
    "# To support ResNet18 and ResNet34 for tensorflow.keras\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from util.preprocess import rescale_0_to_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Enum):\n",
    "        vgg16 = 1\n",
    "        resnet18 = 2\n",
    "        resnet34 = 3\n",
    "        mobilenetV2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uFuIiQp2zVUF"
   },
   "outputs": [],
   "source": [
    "# ===============================================DEFINE YOUR ARGUMENTS=================================================\n",
    "if not isGoogleColab():\n",
    "    ARG_DATASET_DIR='/hdd/data/radioterapia/ciolaplata'\n",
    "# folder under ARG_DATASET_DIR path.\n",
    "ARG_RANDOM_SEED = 23456\n",
    "ARG_TFDATASET_FOLDER=f'tfds.2019-2018-2017.localnorm.DS10%.{ARG_RANDOM_SEED}.gammaGT95.unsersampled.fold0'\n",
    "# ARG_TFDATASET_FOLDER=f'tfds.2018.localnorm.DS10%.{ARG_RANDOM_SEED}.fold0'\n",
    "# if False only training and validation partition are created.\n",
    "ARG_TEST_PARTITION=False\n",
    "ARG_NETWORK=CNN.resnet18\n",
    "ARG_RESNET_USE_BN=True\n",
    "\n",
    "# number of continuous epochs without improvement on validation\n",
    "ARG_EPOCHS_WO_IMPROVEMENT=20 # 20 for 2019 only, 10 for 2019+2018, 30 for 2019+2018 for MobileNetV2\n",
    "initial_epochs = 10 # 10 for 2019 only, 5 for 2019+2018\n",
    "# maximum fine-tuning epochs\n",
    "ARG_MAX_FINE_TUNING_EPOCHS=200\n",
    "# 0: use custom LR, 1: use ReduceLROnPlateau\n",
    "ARG_LR_SCHEDULE=1\n",
    "ARG_LR_PATIENCE=10 # only applies if ARG_LR_SCHEDULE is 1. Equals to 10 except for MobileNetV2 that requires 15+\n",
    "ARG_MIN_DELTA_MAE=0.01\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "ARG_DATA_AUGMENTATION=False\n",
    "# perform data augmentation of images with a gamma value lower than gamma_augment\n",
    "ARG_GAMMA_AUGMENT=97.0\n",
    "# set this value based on the ARG_OVERSAMPLING_FACTOR value in tf2_oversampling_dicom_files.py\n",
    "# 1.0 means transform each and every image, with a lower value than 1.0 means that training will include unmodified (not transformed)\n",
    "# images.\n",
    "ARG_AUGMENT_PROBABILITY=0.75 # con 0.85 para el dataset tfds.2019.localnorm.ovs95x8.0 no transformo 93*(1+8)*0.15=125 imágenes  \n",
    "add_regularizers=False\n",
    "## Fine-tune from this layer onwards\n",
    "# fine_tune_at = 281 # InceptionV3, fine-tuning\n",
    "# fine_tune_at = 102 # InceptionV3, not so fine-tuning\n",
    "# fine_tune_at = 74 # resnet34 stage3\n",
    "# fine_tune_at = 129 # resnet34 stage4\n",
    "if ARG_NETWORK == CNN.vgg16:\n",
    "    fine_tune_at = 11 # VGG16\n",
    "elif ARG_NETWORK == CNN.resnet18:\n",
    "    # fine_tune_at = 46 # resnet18 stage3\n",
    "    fine_tune_at = 27 # resnet18 stage2\n",
    "elif ARG_NETWORK == CNN.resnet34:\n",
    "    fine_tune_at = 73 # resnet34 stage3\n",
    "else:\n",
    "    fine_tune_at = 117 # MobileNetV2 block_12_add para atrás\n",
    "ARG_TRANSFORM_GAMMA=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v77rlkCKW0IJ"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GoKGm1duzgk"
   },
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KVh7rDVAuW8Y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "tf.random.set_seed(ARG_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1KR9xb8NyFTC"
   },
   "outputs": [],
   "source": [
    "def _tfrecord_dataset_type_from_folder(folder, dataset_type, ext='.tfrecords'):\n",
    "    tfrecords = [os.path.join(folder, n)\n",
    "                 for n in os.listdir(folder) if n.startswith(dataset_type) and n.endswith(ext)]\n",
    "    return tf.data.TFRecordDataset(tfrecords)\n",
    "\n",
    "tfdataset_dir = os.path.join(ARG_DATASET_DIR, ARG_TFDATASET_FOLDER)\n",
    "# type(raw_train) is tensorflow.python.data.ops.readers.TFRecordDatasetV2\n",
    "raw_train = _tfrecord_dataset_type_from_folder(tfdataset_dir, 'train')\n",
    "raw_validation = _tfrecord_dataset_type_from_folder(tfdataset_dir, 'validation')\n",
    "if ARG_TEST_PARTITION:\n",
    "    raw_test = _tfrecord_dataset_type_from_folder(tfdataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o29EfE-p0g5X"
   },
   "source": [
    "The resulting `tf.data.Dataset` objects contain `(image, label)` pairs where the images have variable shape and 3 channels, and the label is a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GIys1_zY1S9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n",
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "if ARG_TEST_PARTITION:\n",
    "    print(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T1Gm1wdHyFTK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training part = 1270.\n",
      "Number of images in validation part = 318.\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of images in training part = {sum(1 for _ in raw_train)}.')\n",
    "print(f'Number of images in validation part = {sum(1 for _ in raw_validation)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ar8TNzTSyFTS"
   },
   "outputs": [],
   "source": [
    "def _parse_image_function(example_proto, img_size, normalization_fn, data_augmentation=False, augment_probability=1.0, transform_gamma=False):\n",
    "    # Create a dictionary describing the features.\n",
    "    image_feature_description = {\"image/filename\": tf.io.FixedLenFeature((), tf.string),\n",
    "                \"image/encoded\": tf.io.FixedLenFeature((), tf.string),\n",
    "                \"image/format\": tf.io.FixedLenFeature((), tf.string),\n",
    "                \"image/gamma_index\": tf.io.FixedLenFeature((), tf.float32),\n",
    "                \"image/height\": tf.io.FixedLenFeature((), tf.int64),\n",
    "                \"image/width\": tf.io.FixedLenFeature((), tf.int64)}\n",
    "    \n",
    "    def image_augment(image):\n",
    "        radian = ((np.random.random()-.50)*10 / 360) * np.pi\n",
    "        # tfa.image.transform_ops.rotate(image, radian) is an alias\n",
    "        image = tfa.image.rotate(image, radian)\n",
    "        # image = tf.image.random_flip_left_right(image)\n",
    "        image = random_translation(image)\n",
    "        return image\n",
    "\n",
    "    # Now, globally set everything to run eagerly\n",
    "    # The following doesn't set to eager mode:\n",
    "    # UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set,\n",
    "    # this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
    "    # tf.config.run_functions_eagerly(True)\n",
    "\n",
    "    # Executing eagerly = False here!\n",
    "    # numpy is only supported in eager mode. If you are in graph mode, it will not be supported.\n",
    "    # In eager execution the shape is always fully-known.\n",
    "    # print('Executing eagerly = {}'.format(tf.executing_eagerly()))\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(parsed[\"image/encoded\"], channels=3)\n",
    "    # print(type(image), image.shape, image.dtype) # <class 'tensorflow.python.framework.ops.Tensor'> (None, None, 3) <dtype: 'uint8'>\n",
    "\n",
    "    gamma = tf.cast(\n",
    "        parsed[\"image/gamma_index\"],\n",
    "        tf.float32)\n",
    "    # print(type(gamma), gamma.shape, gamma.dtype) # <class 'tensorflow.python.framework.ops.Tensor'> () <dtype: 'float32'>\n",
    "\n",
    "    image = normalization_fn(image)\n",
    "\n",
    "    image = tf.image.resize(image, (img_size, img_size))\n",
    "    print(type(image), image.shape, image.dtype)\n",
    "\n",
    "    if data_augmentation and augment_probability >= random.uniform(0, 1):\n",
    "        gamma_augment = tf.constant(ARG_GAMMA_AUGMENT)\n",
    "        image = tf.cond(tf.math.less(gamma, gamma_augment)\n",
    "                        , lambda: image_augment(image)\n",
    "                        , lambda: image)\n",
    "\n",
    "    # normalizo antes de transformar\n",
    "    # image = normalization_fn(image)\n",
    "    \n",
    "    #label is a tensor of an array of single tf.int64 arrays.\n",
    "    #label = tf.cast(\n",
    "    #    tf.reshape(parsed[\"image/class/label\"], [-1]),\n",
    "    #    tf.int64)\n",
    "\n",
    "    # assert tf.executing_eagerly() FAILS\n",
    "    # parsed[\"image/filename\"] is a Tensor and not an EagerTensor because we are in a map function,\n",
    "    # because in 2.0, code inside Datasets maps is turned into a subgraph for speed, just as it was in 1.x eager\n",
    "    # execution. You generally want to avoid Python inside your data pipeline.\n",
    "    # So, if I invoke parsed[\"image/filename\"].numpy().decode('utf-8') to get the filename string the error\n",
    "    # \"AttributeError: 'Tensor' object has no attribute 'numpy'\" is thrown, hence I return a tensor.\n",
    "    filename = parsed[\"image/filename\"]\n",
    "\n",
    "    if transform_gamma:\n",
    "        gamma = 60.0 - (105 - gamma)\n",
    "                    \n",
    "    return image, gamma, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CyTNIMaeyFTX"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 256 # All images will be resized to 256x256\n",
    "if ARG_NETWORK == CNN.mobilenetV2: IMG_SIZE = 224\n",
    "\n",
    "normalization_fn = rescale_0_to_1 # rescale_min_1_to_1\n",
    "# normalization_fn = tf.image.per_image_standardization # loss y mae en validación reportan números muy grandes,\n",
    "# no así en training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SFZ6ZW7KSXP9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'> (256, 256, 3) <dtype: 'float32'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> (256, 256, 3) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "num_workers = 8\n",
    "\n",
    "# assert tf.executing_eagerly()\n",
    "if ARG_DATA_AUGMENTATION:\n",
    "    print(\"Training with image augmentation.\")\n",
    "    \n",
    "train = raw_train.map(lambda e: _parse_image_function(e, IMG_SIZE, normalization_fn, ARG_DATA_AUGMENTATION, ARG_AUGMENT_PROBABILITY,\n",
    "                                                      transform_gamma=ARG_TRANSFORM_GAMMA),\n",
    "                      num_parallel_calls=num_workers)\n",
    "validation = raw_validation.map(lambda e: _parse_image_function(e, IMG_SIZE, normalization_fn, transform_gamma=ARG_TRANSFORM_GAMMA),\n",
    "                                num_parallel_calls=num_workers)\n",
    "if ARG_TEST_PARTITION:\n",
    "    test = raw_test.map(lambda e: _parse_image_function(e, IMG_SIZE, normalization_fn),\n",
    "                        num_parallel_calls=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yic-I66m6Isv"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = 2 * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "p3UUPdm86LNC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing eagerly = True\n",
      "<PrefetchDataset shapes: ((None, 256, 256, 3), (None,), (None,)), types: (tf.float32, tf.float32, tf.string)>\n",
      "<PrefetchDataset shapes: ((None, 256, 256, 3), (None,), (None,)), types: (tf.float32, tf.float32, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "print('Executing eagerly = {}'.format(tf.executing_eagerly()))\n",
    "\n",
    "# <PrefetchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.int64)>\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER_SIZE)\n",
    "print(train_batches)\n",
    "validation_batches = validation.batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER_SIZE)\n",
    "print(validation_batches)\n",
    "# <BatchDataset shapes: ((None, 224, 224, 3), (None, 1)), types: (tf.float32, tf.int64)>\n",
    "if ARG_TEST_PARTITION:\n",
    "    test_batches = test.batch(BATCH_SIZE)\n",
    "    print(test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02rJpcFtChP0"
   },
   "source": [
    "Inspect a batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iknFo3ELBVho"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 256, 256, 3]), TensorShape([32]), TensorShape([32]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch, filename_batch in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "image_batch.shape, label_batch.shape, filename_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5pIy5ehM4YzC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma=98.31, filename=/hdd/data/radioterapia/ciolaplata/2018/1.3.6.1.4.1.9590.100.1.2.262393207512012179817573807432937652820.dcm\n",
      "image shape = (256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display 2nd image in the batch\n",
    "gamma_value = label_batch[8].numpy()\n",
    "filename = filename_batch[8].numpy().decode('utf-8')\n",
    "print(f'gamma={gamma_value:2.2f}, filename={filename}')\n",
    "# if pixel values are float they have to be in [0, 1] range, if they are integer they have to be in the [0, 255] range,\n",
    "# else pixel values are truncated.\n",
    "im = image_batch[8].numpy()\n",
    "plt.imshow(im)\n",
    "print(\"image shape = {}\".format(im.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[:,:,0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkH-kazQecHB"
   },
   "source": [
    "## Create the base model from the pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aiLcQ7JkDM6U"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "if ARG_NETWORK==CNN.resnet18:\n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    base_model = ResNet18(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "    # no transfer learning\n",
    "    # base_model = ResNet18(input_shape=IMG_SHAPE, include_top=False)\n",
    "\n",
    "elif ARG_NETWORK==CNN.resnet34:\n",
    "    ResNet34, preprocess_input = Classifiers.get('resnet34')\n",
    "    base_model = ResNet34(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "elif ARG_NETWORK== CNN.mobilenetV2:\n",
    "    ## Create the base model from the pre-trained model MobileNet V2\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   # alpha=1.4,\n",
    "                                                   weights='imagenet',\n",
    "                                                   include_top=False)\n",
    "\n",
    "else:\n",
    "    base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                                   weights='imagenet',\n",
    "                                                   include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqcsxoJIEVXZ"
   },
   "source": [
    "This feature extractor converts each `160x160x3` image into a `5x5x1280` block of features. See what it does to the example batch of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Y-2LJL0EEUcx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlx56nQtfe8Y"
   },
   "source": [
    "## Feature extraction\n",
    "In this step, you will freeze the convolutional base created from the previous step and to use as a feature extractor. Additionally, you add a classifier on top of it and train the top-level classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMLieHBCwil"
   },
   "source": [
    "### Freeze the convolutional base\n",
    "\n",
    "It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. MobileNet V2 has many layers, so setting the entire model's trainable flag to False will freeze all the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OTCJH4bphOeo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_data (BatchNormalization)\n",
      "bn0 (BatchNormalization)\n",
      "stage1_unit1_bn1 (BatchNormalization)\n",
      "stage1_unit1_bn2 (BatchNormalization)\n",
      "stage1_unit2_bn1 (BatchNormalization)\n",
      "stage1_unit2_bn2 (BatchNormalization)\n",
      "stage2_unit1_bn1 (BatchNormalization)\n",
      "stage2_unit1_bn2 (BatchNormalization)\n",
      "stage2_unit2_bn1 (BatchNormalization)\n",
      "stage2_unit2_bn2 (BatchNormalization)\n",
      "stage3_unit1_bn1 (BatchNormalization)\n",
      "stage3_unit1_bn2 (BatchNormalization)\n",
      "stage3_unit2_bn1 (BatchNormalization)\n",
      "stage3_unit2_bn2 (BatchNormalization)\n",
      "stage4_unit1_bn1 (BatchNormalization)\n",
      "stage4_unit1_bn2 (BatchNormalization)\n",
      "stage4_unit2_bn1 (BatchNormalization)\n",
      "stage4_unit2_bn2 (BatchNormalization)\n",
      "bn1 (BatchNormalization)\n"
     ]
    }
   ],
   "source": [
    "if not (ARG_NETWORK == CNN.resnet18 or ARG_NETWORK == CNN.resnet34):\n",
    "    base_model.trainable = False\n",
    "else:\n",
    "    # resnet\n",
    "    for layer in base_model.layers:\n",
    "            if layer.__class__.__name__ != \"BatchNormalization\":\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                print(f\"{layer.name} ({layer.__class__.__name__})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KpbzSmPkDa-N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 11,186,889\n",
      "Trainable params: 7,939\n",
      "Non-trainable params: 11,178,950\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7RFyBW06yFUC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer conv0 has no regularizer.\n",
      "layer stage1_unit1_conv1 has no regularizer.\n",
      "layer stage1_unit1_conv2 has no regularizer.\n",
      "layer stage1_unit1_sc has no regularizer.\n",
      "layer stage1_unit2_conv1 has no regularizer.\n",
      "layer stage1_unit2_conv2 has no regularizer.\n",
      "layer stage2_unit1_conv1 has no regularizer.\n",
      "layer stage2_unit1_conv2 has no regularizer.\n",
      "layer stage2_unit1_sc has no regularizer.\n",
      "layer stage2_unit2_conv1 has no regularizer.\n",
      "layer stage2_unit2_conv2 has no regularizer.\n",
      "layer stage3_unit1_conv1 has no regularizer.\n",
      "layer stage3_unit1_conv2 has no regularizer.\n",
      "layer stage3_unit1_sc has no regularizer.\n",
      "layer stage3_unit2_conv1 has no regularizer.\n",
      "layer stage3_unit2_conv2 has no regularizer.\n",
      "layer stage4_unit1_conv1 has no regularizer.\n",
      "layer stage4_unit1_conv2 has no regularizer.\n",
      "layer stage4_unit1_sc has no regularizer.\n",
      "layer stage4_unit2_conv1 has no regularizer.\n",
      "layer stage4_unit2_conv2 has no regularizer.\n"
     ]
    }
   ],
   "source": [
    "from add_regularization import add_regularization\n",
    "# adds a tf.keras.regularizers.l2(0.0001)\n",
    "#\"kernel_regularizer\":{\n",
    "#                        \"class_name\": \"L1L2\",\n",
    "#                        \"config\": {\n",
    "#                            \"l1\": 0,\n",
    "#                            \"l2\": 0.0001\n",
    "#                        }\n",
    "#                     }\n",
    "if add_regularizers:\n",
    "    base_model = add_regularization(base_model)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    for attr in ['kernel_regularizer']:\n",
    "        if hasattr(layer, attr):\n",
    "            if getattr(layer, attr) is None:\n",
    "                print('layer {} has no regularizer.'.format(layer.name))\n",
    "            else:\n",
    "                print('layer {} has a regularizer {}.'.format(layer.name, getattr(layer, attr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "avX9AnbJyFUH"
   },
   "outputs": [],
   "source": [
    "# display the weights of some layers\n",
    "l = 1\n",
    "for layer in base_model.layers:\n",
    "    # print('layer {:3d}, name: {}'.format(l, layer.name))\n",
    "    if layer.name == \"expanded_conv_project\":\n",
    "        weights = layer.get_weights()\n",
    "        print(layer.get_config(), weights, weights[0].shape)\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dLnpMF5KOALm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzmSozfKDM6W"
   },
   "source": [
    "Stack the feature extractor, and these two layers using a `tf.keras.Sequential` model for network architectures other than ResNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Wv4afXKj6cVa"
   },
   "outputs": [],
   "source": [
    "num_activation_filters = 512\n",
    "if ARG_NETWORK == CNN.mobilenetV2:\n",
    "    num_activation_filters = 1280\n",
    "\n",
    "if not (ARG_NETWORK == CNN.resnet18 or ARG_NETWORK == CNN.resnet34):\n",
    "    # Pablo March 10: add sigmoid\n",
    "    # WARNING: adding the activation function causes loss to keep close to 0.5 and does not decrease.\n",
    "    # prediction_layer = keras.layers.Dense(1, activation='sigmoid') # para obtener probabilidades y no logits\n",
    "\n",
    "    # https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes\n",
    "    # https://stackoverflow.com/questions/58627411/how-to-use-inception-network-for-regression\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    fc1 = keras.layers.Dense(num_activation_filters, activation='relu')\n",
    "    #fc2 = keras.layers.Dense(num_activation_filders, activation='relu')\n",
    "    #dropout = keras.layers.Dropout(rate=0.05) # no funciona\n",
    "    # and a linear output layer (regression)\n",
    "\n",
    "    bn = keras.layers.BatchNormalization() # same as ResNet18 but with VGG16 is worst.\n",
    "\n",
    "    prediction_layer = keras.layers.Dense(1, activation='linear')\n",
    "    # and a logistic layer -- let's say we have 200 classes (classification)\n",
    "    # prediction_layer = Dense(200, activation='softmax')(x)\n",
    "\n",
    "    # Up to March 27, 2020\n",
    "    # prediction_layer = keras.layers.Dense(1)\n",
    "    prediction_batch = prediction_layer(feature_batch_average)\n",
    "    print(prediction_batch.shape)\n",
    "\n",
    "    # Now stack the feature extractor, and these two layers using a `tf.keras.Sequential` model:\n",
    "    model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      fc1,\n",
    "      #bn,\n",
    "      #dropout,\n",
    "      #fc2,\n",
    "      prediction_layer\n",
    "    ])\n",
    "    \n",
    "else:\n",
    "    avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    out = tf.keras.layers.Dense(num_activation_filters, activation=\"relu\")(avg) # CHANGE to use avg pool only or avg pool + max pool\n",
    "    if ARG_RESNET_USE_BN:\n",
    "        # no observé mejoras en 2017 agregando esta bn layer, pero sí observé mejoras en 4 de 5 folds de cross validation\n",
    "        # en 2019+2017\n",
    "        out = tf.keras.layers.BatchNormalization()(out)\n",
    "    prediction_layer = tf.keras.layers.Dense(1, activation='linear')(out)\n",
    "    model = keras.models.Model(inputs=base_model.input, outputs=prediction_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0ylJXE_kRLi"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "You must compile the model before training it.  Since there are two classes, use a binary cross-entropy loss with `from_logits=True` since the model provides a linear output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RpR8HdyMhukJ"
   },
   "outputs": [],
   "source": [
    "# mse = square(y_true - y_pred)\n",
    "# mae = loss = abs(y_true - y_pred)\n",
    "# mape = 100 * abs(y_true - y_pred) / y_true\n",
    "# mae y mape son similares, no iguales, por eso tomo MAE que es el promedio de la diferencia absoluta entre el\n",
    "# gamma real y el gamma predicho\n",
    "# optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate, momentum=0.95)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "I8ARiyMFsgbH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 11,452,106\n",
      "Trainable params: 272,132\n",
      "Non-trainable params: 11,179,974\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxvgOYTDSWTx"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hlHEavK7DUI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in train partition: 1270, in validation: 318.\n"
     ]
    }
   ],
   "source": [
    "num_train = sum(1 for _ in raw_train)\n",
    "num_val = sum(1 for _ in raw_validation)\n",
    "print(f'Number of images in train partition: {num_train}, in validation: {num_val}.')\n",
    "if ARG_TEST_PARTITION:\n",
    "    num_test = sum(1 for _ in raw_test)\n",
    "    print(f'Number of images in test partiton: {num_test}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Om4O3EESkab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
    "validation_steps=20\n",
    "\n",
    "# projects out just the first two components.\n",
    "tmp_validation_batches = validation_batches.map(lambda image, gamma, filename: (image, gamma))\n",
    "print(tmp_validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8cYT1c48CuSd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/20 [==============>...............] - ETA: 0s - loss: 98.7718 - mse: 9757.0762WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/20 [==============>...............] - 0s 35ms/step - loss: 98.7718 - mse: 9757.0762\n",
      "initial loss: 98.77\n",
      "initial mape: 9757.08\n"
     ]
    }
   ],
   "source": [
    "loss0 = mse0 = 0\n",
    "loss0, mse0 = model.evaluate(tmp_validation_batches, steps = validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial mape: {:.2f}\".format(mse0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JsaRFlZ9B6WK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "# projects out just the first two components.\n",
    "tmp_train_batches = train_batches.map(lambda image, gamma, filename: (image, gamma))\n",
    "print(tmp_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XTtp6LG7yFUw"
   },
   "outputs": [],
   "source": [
    "# Implement callback function to stop training\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, wait_epochs):\n",
    "        self.__wait_epochs = wait_epochs\n",
    "        self.__latest_peak_mae = 50.0 # MobileNetV2 requires such a high value because it improves very slowly.\n",
    "        self.__waited_epochs = 0\n",
    "        self.__saved_model_file = None\n",
    "        self.__saved_model = None\n",
    "        \n",
    "    def stopTraining(self, epoch, val_mae):\n",
    "        stop_early = False\n",
    "        best_mae = False\n",
    "        # check for early stop\n",
    "        if val_mae < self.__latest_peak_mae and abs(val_mae - self.__latest_peak_mae) > ARG_MIN_DELTA_MAE:\n",
    "            best_mae = True\n",
    "            self.__latest_peak_mae = val_mae\n",
    "            print(f\"\\nNew peak val_mae reached: {val_mae:6.3}\")\n",
    "\n",
    "            t = time.time()\n",
    "            dir = os.path.join(ARG_DATASET_DIR, \"models\")\n",
    "            save_model_path = \"{}/{}.{}.{}.h5\".format(dir, int(t), ARG_NETWORK.name, ARG_RANDOM_SEED)\n",
    "            print(save_model_path)\n",
    "            # Either 'tf' or 'h5', indicating whether to save the model to Tensorflow SavedModel or HDF5. Defaults to 'tf' \n",
    "            # in TF 2.X, and 'h5' in TF 1.X.            \n",
    "            model.save(save_model_path, save_format='h5')\n",
    "            # borro el archivo del modelo anterior\n",
    "            if self.__saved_model_file is not None:\n",
    "                os.remove(self.__saved_model_file)\n",
    "            self.__saved_model_file = save_model_path\n",
    "            reloaded_model = tf.keras.models.load_model(save_model_path)\n",
    "            self.__saved_model = reloaded_model\n",
    "\n",
    "        if val_mae > self.__latest_peak_mae or not best_mae:\n",
    "            # Si llevo N+ epochs sin mejora\n",
    "            if self.__waited_epochs >= self.__wait_epochs:\n",
    "                print(\"\\nStopping early at epoch {0} with saved peak mae {1:10.8}\"\n",
    "                      .format(epoch + 1, self.__latest_peak_mae))\n",
    "                stop_early = True\n",
    "            \n",
    "            self.__waited_epochs += 1\n",
    "            \n",
    "        else:\n",
    "            self.__latest_peak_mae = val_mae\n",
    "            # Reset waited epochs.\n",
    "            print(\"waiting epochs reset.\")\n",
    "            self.reset_waited_epochs()\n",
    "            \n",
    "        return stop_early\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # print('\\nTraining: epoch {} ends at {}'.format(epoch, datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "        if self.stopTraining(epoch, logs.get('val_loss')):\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    @property\n",
    "    def saved_model_file(self):\n",
    "        return self.__saved_model_file\n",
    "    \n",
    "    @property\n",
    "    def saved_model(self):\n",
    "        return self.__saved_model\n",
    "\n",
    "    def reset_waited_epochs(self):\n",
    "        self.__waited_epochs = 0;\n",
    "    \n",
    "\n",
    "# Instantiate a callback object\n",
    "callbackObj = MyCallback(ARG_EPOCHS_WO_IMPROVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "MZyPn887yFUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 97.2455 - mse: 9460.7031 - val_loss: 97.4839 - val_mse: 9504.3164\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 93.6195 - mse: 8774.4990 - val_loss: 88.9476 - val_mse: 7912.8843\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 86.2408 - mse: 7459.7529 - val_loss: 80.0307 - val_mse: 6406.1196\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 74.5560 - mse: 5600.4863 - val_loss: 69.7332 - val_mse: 4863.9102\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 58.3957 - mse: 3476.2017 - val_loss: 44.1261 - val_mse: 1948.3016\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 37.7299 - mse: 1516.9921 - val_loss: 21.8302 - val_mse: 477.7578\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 16.8803 - mse: 405.1902 - val_loss: 41.9321 - val_mse: 1762.2065\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 4.7418 - mse: 40.2477 - val_loss: 20.4754 - val_mse: 420.5413\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 2.5664 - mse: 11.0972 - val_loss: 21.8325 - val_mse: 477.9772\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 1.7770 - mse: 5.5404 - val_loss: 18.8931 - val_mse: 358.5294\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tmp_train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=tmp_validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd94CKImf8vi"
   },
   "source": [
    "### Learning curves\n",
    "\n",
    "Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNet V2 base model as a fixed feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "zvmYWOgoyFU4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "4Po3M6UrGvKr"
   },
   "outputs": [],
   "source": [
    "# Pablo Feb 25:\n",
    "# Python never implicitly copies objects. When you set list2 = list1, you are making them refer to the same exact\n",
    "# list object, so when you mutate it, all references to it keep referring to the object in its current state.\n",
    "mse = history.history['mse'].copy()\n",
    "val_mse = history.history['val_mse'].copy()\n",
    "\n",
    "loss = history.history['loss'].copy()\n",
    "val_loss = history.history['val_loss'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "53OTCh3jnbwV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(mse, label='Training MSE')\n",
    "plt.plot(val_mse, label='Validation MSE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim([0,50])\n",
    "plt.title('Training and Validation MSE')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0,10])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqwV-CRdS6Nv"
   },
   "source": [
    "## Fine tuning\n",
    "In the feature extraction experiment, you were only training a few layers on top of a VGG16 base model. The weights of the pre-trained network were **not** updated during training.\n",
    "\n",
    "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n",
    "\n",
    "Note: This should only be attempted after you have trained the top-level classifier with the pre-trained model set to non-trainable. If you add a randomly initialized classifier on top of a pre-trained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) and your pre-trained model will forget what it has learned.\n",
    "\n",
    "Also, you should try to fine-tune a small number of top layers rather than the whole VGG16 model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPXnzUK0QonF"
   },
   "source": [
    "### Un-freeze the top layers of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfxv_ifotQak"
   },
   "source": [
    "All you need to do is unfreeze the `base_model` and set the bottom layers to be un-trainable. Then, you should recompile the model (necessary for these changes to take effect), and resume training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "4nzcagVitLQm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer   1, name: data\n",
      "layer   2, name: bn_data\n",
      "layer   3, name: zero_padding2d\n",
      "layer   4, name: conv0\n",
      "layer   5, name: bn0\n",
      "layer   6, name: relu0\n",
      "layer   7, name: zero_padding2d_1\n",
      "layer   8, name: pooling0\n",
      "layer   9, name: stage1_unit1_bn1\n",
      "layer  10, name: stage1_unit1_relu1\n",
      "layer  11, name: zero_padding2d_2\n",
      "layer  12, name: stage1_unit1_conv1\n",
      "layer  13, name: stage1_unit1_bn2\n",
      "layer  14, name: stage1_unit1_relu2\n",
      "layer  15, name: zero_padding2d_3\n",
      "layer  16, name: stage1_unit1_conv2\n",
      "layer  17, name: stage1_unit1_sc\n",
      "layer  18, name: add\n",
      "layer  19, name: stage1_unit2_bn1\n",
      "layer  20, name: stage1_unit2_relu1\n",
      "layer  21, name: zero_padding2d_4\n",
      "layer  22, name: stage1_unit2_conv1\n",
      "layer  23, name: stage1_unit2_bn2\n",
      "layer  24, name: stage1_unit2_relu2\n",
      "layer  25, name: zero_padding2d_5\n",
      "layer  26, name: stage1_unit2_conv2\n",
      "layer  27, name: add_1\n",
      "layer  28, name: stage2_unit1_bn1\n",
      "layer  29, name: stage2_unit1_relu1\n",
      "layer  30, name: zero_padding2d_6\n",
      "layer  31, name: stage2_unit1_conv1\n",
      "layer  32, name: stage2_unit1_bn2\n",
      "layer  33, name: stage2_unit1_relu2\n",
      "layer  34, name: zero_padding2d_7\n",
      "layer  35, name: stage2_unit1_conv2\n",
      "layer  36, name: stage2_unit1_sc\n",
      "layer  37, name: add_2\n",
      "layer  38, name: stage2_unit2_bn1\n",
      "layer  39, name: stage2_unit2_relu1\n",
      "layer  40, name: zero_padding2d_8\n",
      "layer  41, name: stage2_unit2_conv1\n",
      "layer  42, name: stage2_unit2_bn2\n",
      "layer  43, name: stage2_unit2_relu2\n",
      "layer  44, name: zero_padding2d_9\n",
      "layer  45, name: stage2_unit2_conv2\n",
      "layer  46, name: add_3\n",
      "layer  47, name: stage3_unit1_bn1\n",
      "layer  48, name: stage3_unit1_relu1\n",
      "layer  49, name: zero_padding2d_10\n",
      "layer  50, name: stage3_unit1_conv1\n",
      "layer  51, name: stage3_unit1_bn2\n",
      "layer  52, name: stage3_unit1_relu2\n",
      "layer  53, name: zero_padding2d_11\n",
      "layer  54, name: stage3_unit1_conv2\n",
      "layer  55, name: stage3_unit1_sc\n",
      "layer  56, name: add_4\n",
      "layer  57, name: stage3_unit2_bn1\n",
      "layer  58, name: stage3_unit2_relu1\n",
      "layer  59, name: zero_padding2d_12\n",
      "layer  60, name: stage3_unit2_conv1\n",
      "layer  61, name: stage3_unit2_bn2\n",
      "layer  62, name: stage3_unit2_relu2\n",
      "layer  63, name: zero_padding2d_13\n",
      "layer  64, name: stage3_unit2_conv2\n",
      "layer  65, name: add_5\n",
      "layer  66, name: stage4_unit1_bn1\n",
      "layer  67, name: stage4_unit1_relu1\n",
      "layer  68, name: zero_padding2d_14\n",
      "layer  69, name: stage4_unit1_conv1\n",
      "layer  70, name: stage4_unit1_bn2\n",
      "layer  71, name: stage4_unit1_relu2\n",
      "layer  72, name: zero_padding2d_15\n",
      "layer  73, name: stage4_unit1_conv2\n",
      "layer  74, name: stage4_unit1_sc\n",
      "layer  75, name: add_6\n",
      "layer  76, name: stage4_unit2_bn1\n",
      "layer  77, name: stage4_unit2_relu1\n",
      "layer  78, name: zero_padding2d_16\n",
      "layer  79, name: stage4_unit2_conv1\n",
      "layer  80, name: stage4_unit2_bn2\n",
      "layer  81, name: stage4_unit2_relu2\n",
      "layer  82, name: zero_padding2d_17\n",
      "layer  83, name: stage4_unit2_conv2\n",
      "layer  84, name: add_7\n",
      "layer  85, name: bn1\n",
      "layer  86, name: relu1\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Pablo Feb 25: con este loop me aseguro que las capas que en la próxima celda *NO* pongo como layer.trainable = False sean\n",
    "# trainable.\n",
    "l = 1\n",
    "for layer in base_model.layers:\n",
    "    print('layer {:3d}, name: {}'.format(l, layer.name))\n",
    "    if layer.__class__.__name__ != \"BatchNormalization\":\n",
    "        layer.trainable =  True\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-4HgVAacRs5v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  86\n",
      "layer   1, name: data set to not trainable.\n",
      "layer   3, name: zero_padding2d set to not trainable.\n",
      "layer   4, name: conv0 set to not trainable.\n",
      "layer   6, name: relu0 set to not trainable.\n",
      "layer   7, name: zero_padding2d_1 set to not trainable.\n",
      "layer   8, name: pooling0 set to not trainable.\n",
      "layer  10, name: stage1_unit1_relu1 set to not trainable.\n",
      "layer  11, name: zero_padding2d_2 set to not trainable.\n",
      "layer  12, name: stage1_unit1_conv1 set to not trainable.\n",
      "layer  14, name: stage1_unit1_relu2 set to not trainable.\n",
      "layer  15, name: zero_padding2d_3 set to not trainable.\n",
      "layer  16, name: stage1_unit1_conv2 set to not trainable.\n",
      "layer  17, name: stage1_unit1_sc set to not trainable.\n",
      "layer  18, name: add set to not trainable.\n",
      "layer  20, name: stage1_unit2_relu1 set to not trainable.\n",
      "layer  21, name: zero_padding2d_4 set to not trainable.\n",
      "layer  22, name: stage1_unit2_conv1 set to not trainable.\n",
      "layer  24, name: stage1_unit2_relu2 set to not trainable.\n",
      "layer  25, name: zero_padding2d_5 set to not trainable.\n",
      "layer  26, name: stage1_unit2_conv2 set to not trainable.\n",
      "layer  27, name: add_1 set to not trainable.\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "l = 1\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    if layer.__class__.__name__ != \"BatchNormalization\":\n",
    "        print('layer {:3d}, name: {} set to not trainable.'.format(l, layer.name))\n",
    "        layer.trainable = False\n",
    "    l += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Uk1dgsxT0IS"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "Compile the model using a much lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "AVvlrXb9yFVH"
   },
   "outputs": [],
   "source": [
    "# This function keeps the learning rate at 0.001 for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def lr_scheduler(epoch):\n",
    "    lr = base_learning_rate\n",
    "    #k = 0.15\n",
    "    #if epoch >= 10 and epoch <= 40:\n",
    "    #    lr = tf.math.exp(k * (10 - epoch)) * base_learning_rate\n",
    "    #    print(\"\\nlearning rate: %.8f\"%(lr))\n",
    "    if epoch >= 10 and epoch <= 30:\n",
    "        lr = base_learning_rate/10\n",
    "    elif epoch > 30 and epoch <= 60:\n",
    "        lr = base_learning_rate/100\n",
    "    elif epoch > 60:\n",
    "        lr = base_learning_rate/500\n",
    "    print(\"\\nlearning rate: %.6f\"%(lr))\n",
    "    \n",
    "    return lr\n",
    "    \n",
    "    \n",
    "callbackLR = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "MvJPcR-PIEu2"
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=ARG_LR_PATIENCE, verbose=1, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "NtUnaz0WUDva"
   },
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10, momentum=0.95)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/10, epsilon=1e-08, amsgrad=False)\n",
    "model.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              optimizer = optimizer,\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "WwBWy7J2kZvA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 11,452,106\n",
      "Trainable params: 11,282,180\n",
      "Non-trainable params: 169,926\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "bNXelbMQtonr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5O4jd6TuAG"
   },
   "source": [
    "### Continue training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0foWUN-yDLo_"
   },
   "source": [
    "If you trained to convergence earlier, this step will improve your accuracy by a few percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ECQLkAsFTlun"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/210\n",
      "     40/Unknown - 3s 77ms/step - loss: 1.4695 - mse: 3.5948\n",
      "New peak val_mae reached:   16.4\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152878.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 5s 114ms/step - loss: 1.4695 - mse: 3.5948 - val_loss: 16.3873 - val_mse: 271.2219 - lr: 1.0000e-04\n",
      "Epoch 12/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.1072 - mse: 2.1419\n",
      "New peak val_mae reached:   9.71\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152882.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 1.1072 - mse: 2.1419 - val_loss: 9.7120 - val_mse: 96.2691 - lr: 1.0000e-04\n",
      "Epoch 13/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.9066 - mse: 1.3639 - val_loss: 10.6963 - val_mse: 116.2496 - lr: 1.0000e-04\n",
      "Epoch 14/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8065 - mse: 1.1384\n",
      "New peak val_mae reached:   9.06\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152891.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.8065 - mse: 1.1384 - val_loss: 9.0572 - val_mse: 84.1424 - lr: 1.0000e-04\n",
      "Epoch 15/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7399 - mse: 0.9256\n",
      "New peak val_mae reached:   7.08\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152895.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 106ms/step - loss: 0.7399 - mse: 0.9256 - val_loss: 7.0799 - val_mse: 52.3467 - lr: 1.0000e-04\n",
      "Epoch 16/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6840 - mse: 0.7789\n",
      "New peak val_mae reached:    4.2\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152900.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 106ms/step - loss: 0.6840 - mse: 0.7789 - val_loss: 4.2033 - val_mse: 19.7186 - lr: 1.0000e-04\n",
      "Epoch 17/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6517 - mse: 0.7111\n",
      "New peak val_mae reached:    2.6\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152904.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 0.6517 - mse: 0.7111 - val_loss: 2.5985 - val_mse: 8.9237 - lr: 1.0000e-04\n",
      "Epoch 18/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.6161 - mse: 0.6245 - val_loss: 2.5902 - val_mse: 8.7227 - lr: 1.0000e-04\n",
      "Epoch 19/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5480 - mse: 0.5286\n",
      "New peak val_mae reached:   1.73\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152913.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 112ms/step - loss: 0.5480 - mse: 0.5286 - val_loss: 1.7315 - val_mse: 4.6941 - lr: 1.0000e-04\n",
      "Epoch 20/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5452 - mse: 0.5043\n",
      "New peak val_mae reached:    1.3\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152917.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 0.5452 - mse: 0.5043 - val_loss: 1.3045 - val_mse: 2.4154 - lr: 1.0000e-04\n",
      "Epoch 21/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5148 - mse: 0.4576\n",
      "New peak val_mae reached:   1.17\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152922.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 0.5148 - mse: 0.4576 - val_loss: 1.1652 - val_mse: 2.2189 - lr: 1.0000e-04\n",
      "Epoch 22/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.5390 - mse: 0.4756 - val_loss: 1.5504 - val_mse: 3.1870 - lr: 1.0000e-04\n",
      "Epoch 23/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.5344 - mse: 0.4767 - val_loss: 1.2311 - val_mse: 2.2085 - lr: 1.0000e-04\n",
      "Epoch 24/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.4628 - mse: 0.3516 - val_loss: 1.8635 - val_mse: 4.5019 - lr: 1.0000e-04\n",
      "Epoch 25/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.4649 - mse: 0.3525 - val_loss: 1.6192 - val_mse: 3.4452 - lr: 1.0000e-04\n",
      "Epoch 26/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.4276 - mse: 0.3053 - val_loss: 1.6419 - val_mse: 3.4611 - lr: 1.0000e-04\n",
      "Epoch 27/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.4403 - mse: 0.3125 - val_loss: 1.4674 - val_mse: 2.9235 - lr: 1.0000e-04\n",
      "Epoch 28/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.4079 - mse: 0.2747 - val_loss: 1.2503 - val_mse: 2.1467 - lr: 1.0000e-04\n",
      "Epoch 29/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4060 - mse: 0.2738\n",
      "New peak val_mae reached:   1.06\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152952.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 0.4060 - mse: 0.2738 - val_loss: 1.0650 - val_mse: 1.5649 - lr: 1.0000e-04\n",
      "Epoch 30/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3825 - mse: 0.2504\n",
      "New peak val_mae reached:  0.989\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152956.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 106ms/step - loss: 0.3825 - mse: 0.2504 - val_loss: 0.9893 - val_mse: 1.3909 - lr: 1.0000e-04\n",
      "Epoch 31/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3970 - mse: 0.2574\n",
      "New peak val_mae reached:  0.904\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152961.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 112ms/step - loss: 0.3970 - mse: 0.2574 - val_loss: 0.9044 - val_mse: 1.1941 - lr: 1.0000e-04\n",
      "Epoch 32/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4104 - mse: 0.2690\n",
      "New peak val_mae reached:  0.824\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613152965.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.4104 - mse: 0.2690 - val_loss: 0.8239 - val_mse: 1.0682 - lr: 1.0000e-04\n",
      "Epoch 33/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.3894 - mse: 0.2487 - val_loss: 0.8409 - val_mse: 1.1368 - lr: 1.0000e-04\n",
      "Epoch 34/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3554 - mse: 0.2140 - val_loss: 0.8510 - val_mse: 1.1817 - lr: 1.0000e-04\n",
      "Epoch 35/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3669 - mse: 0.2187 - val_loss: 0.8367 - val_mse: 1.1579 - lr: 1.0000e-04\n",
      "Epoch 36/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3588 - mse: 0.2100 - val_loss: 0.8812 - val_mse: 1.2313 - lr: 1.0000e-04\n",
      "Epoch 37/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3500 - mse: 0.2045 - val_loss: 0.8474 - val_mse: 1.2860 - lr: 1.0000e-04\n",
      "Epoch 38/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3530 - mse: 0.2049 - val_loss: 0.9109 - val_mse: 1.4532 - lr: 1.0000e-04\n",
      "Epoch 39/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3509 - mse: 0.2011 - val_loss: 0.8298 - val_mse: 1.0514 - lr: 1.0000e-04\n",
      "Epoch 40/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3427 - mse: 0.1893 - val_loss: 0.8299 - val_mse: 1.1407 - lr: 1.0000e-04\n",
      "Epoch 41/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3247 - mse: 0.1735 - val_loss: 0.8527 - val_mse: 1.1155 - lr: 1.0000e-04\n",
      "Epoch 42/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3278 - mse: 0.1802\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3278 - mse: 0.1802 - val_loss: 0.8284 - val_mse: 1.0982 - lr: 1.0000e-04\n",
      "Epoch 43/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2912 - mse: 0.1338 - val_loss: 0.8276 - val_mse: 1.0751 - lr: 2.0000e-05\n",
      "Epoch 44/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2887 - mse: 0.1312 - val_loss: 0.8239 - val_mse: 1.0287 - lr: 2.0000e-05\n",
      "Epoch 45/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2539 - mse: 0.1114\n",
      "New peak val_mae reached:   0.81\n",
      "/hdd/data/radioterapia/ciolaplata/models/1613153013.resnet18.23456.h5\n",
      "waiting epochs reset.\n",
      "40/40 [==============================] - 4s 108ms/step - loss: 0.2539 - mse: 0.1114 - val_loss: 0.8097 - val_mse: 1.0479 - lr: 2.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2309 - mse: 0.0868 - val_loss: 0.8018 - val_mse: 1.0100 - lr: 2.0000e-05\n",
      "Epoch 47/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2264 - mse: 0.0870 - val_loss: 0.8061 - val_mse: 1.0211 - lr: 2.0000e-05\n",
      "Epoch 48/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2428 - mse: 0.0913 - val_loss: 0.8252 - val_mse: 1.0292 - lr: 2.0000e-05\n",
      "Epoch 49/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2290 - mse: 0.0843 - val_loss: 0.8048 - val_mse: 1.0169 - lr: 2.0000e-05\n",
      "Epoch 50/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.2320 - mse: 0.0845 - val_loss: 0.8357 - val_mse: 1.0429 - lr: 2.0000e-05\n",
      "Epoch 51/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2261 - mse: 0.0815 - val_loss: 0.8116 - val_mse: 1.0228 - lr: 2.0000e-05\n",
      "Epoch 52/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.2171 - mse: 0.0768 - val_loss: 0.8197 - val_mse: 1.0186 - lr: 2.0000e-05\n",
      "Epoch 53/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2189 - mse: 0.0778 - val_loss: 0.8076 - val_mse: 1.0170 - lr: 2.0000e-05\n",
      "Epoch 54/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2381 - mse: 0.0941 - val_loss: 0.8108 - val_mse: 1.0127 - lr: 2.0000e-05\n",
      "Epoch 55/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2093 - mse: 0.0685\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2093 - mse: 0.0685 - val_loss: 0.8150 - val_mse: 1.0397 - lr: 2.0000e-05\n",
      "Epoch 56/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2055 - mse: 0.0674 - val_loss: 0.8119 - val_mse: 1.0251 - lr: 4.0000e-06\n",
      "Epoch 57/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1896 - mse: 0.0594 - val_loss: 0.8144 - val_mse: 1.0240 - lr: 4.0000e-06\n",
      "Epoch 58/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.1950 - mse: 0.0582 - val_loss: 0.8071 - val_mse: 1.0243 - lr: 4.0000e-06\n",
      "Epoch 59/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1973 - mse: 0.0606 - val_loss: 0.8159 - val_mse: 1.0226 - lr: 4.0000e-06\n",
      "Epoch 60/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1917 - mse: 0.0628 - val_loss: 0.8093 - val_mse: 1.0212 - lr: 4.0000e-06\n",
      "Epoch 61/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.2094 - mse: 0.0683 - val_loss: 0.8107 - val_mse: 1.0197 - lr: 4.0000e-06\n",
      "Epoch 62/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2269 - mse: 0.0825 - val_loss: 0.8091 - val_mse: 1.0208 - lr: 4.0000e-06\n",
      "Epoch 63/210\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.2016 - mse: 0.0668 - val_loss: 0.8078 - val_mse: 1.0221 - lr: 4.0000e-06\n",
      "Epoch 64/210\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2299 - mse: 0.0880 - val_loss: 0.8187 - val_mse: 1.0237 - lr: 4.0000e-06\n",
      "Epoch 65/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2078 - mse: 0.0668\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2078 - mse: 0.0668 - val_loss: 0.8067 - val_mse: 1.0127 - lr: 4.0000e-06\n",
      "Epoch 66/210\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2158 - mse: 0.0715\n",
      "Stopping early at epoch 66 with saved peak mae 0.80973971\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.2158 - mse: 0.0715 - val_loss: 0.8081 - val_mse: 1.0110 - lr: 8.0000e-07\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = ARG_MAX_FINE_TUNING_EPOCHS\n",
    "try:\n",
    "    history.epoch\n",
    "except NameError:\n",
    "    total_epochs = fine_tune_epochs\n",
    "    initial_epoch =  0\n",
    "else:\n",
    "    total_epochs =  (history.epoch[-1]+1) + fine_tune_epochs\n",
    "    initial_epoch =  history.epoch[-1]+1\n",
    "\n",
    "# by default we use custom LR schedule\n",
    "callbacks=[callbackObj, callbackLR]\n",
    "if ARG_LR_SCHEDULE == 1:\n",
    "    callbacks=[callbackObj, reduce_lr]\n",
    "    \n",
    "history_fine = model.fit(tmp_train_batches,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch =  initial_epoch,\n",
    "                         validation_data=tmp_validation_batches,\n",
    "                         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "vjiNEG47yFVY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n"
     ]
    }
   ],
   "source": [
    "print(history_fine.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[271.221923828125,\n",
       " 96.26909637451172,\n",
       " 116.24955749511719,\n",
       " 84.14242553710938,\n",
       " 52.3466682434082,\n",
       " 19.71864891052246,\n",
       " 8.923734664916992,\n",
       " 8.722692489624023,\n",
       " 4.694063186645508,\n",
       " 2.4153902530670166,\n",
       " 2.218850612640381,\n",
       " 3.1870131492614746,\n",
       " 2.2085423469543457,\n",
       " 4.501944065093994,\n",
       " 3.445157766342163,\n",
       " 3.461076498031616,\n",
       " 2.9234845638275146,\n",
       " 2.1466782093048096,\n",
       " 1.5648889541625977,\n",
       " 1.3908907175064087,\n",
       " 1.194067358970642,\n",
       " 1.0682265758514404,\n",
       " 1.1367961168289185,\n",
       " 1.1817200183868408,\n",
       " 1.157913088798523,\n",
       " 1.231309175491333,\n",
       " 1.2859923839569092,\n",
       " 1.45322847366333,\n",
       " 1.0514248609542847,\n",
       " 1.140716314315796,\n",
       " 1.1155073642730713,\n",
       " 1.0981775522232056,\n",
       " 1.0750762224197388,\n",
       " 1.0286941528320312,\n",
       " 1.0479377508163452,\n",
       " 1.0100196599960327,\n",
       " 1.0211154222488403,\n",
       " 1.029241919517517,\n",
       " 1.0169329643249512,\n",
       " 1.0429327487945557,\n",
       " 1.0227899551391602,\n",
       " 1.0186131000518799,\n",
       " 1.017016053199768,\n",
       " 1.012702465057373,\n",
       " 1.0397491455078125,\n",
       " 1.0251026153564453,\n",
       " 1.0239664316177368,\n",
       " 1.0243116617202759,\n",
       " 1.0225975513458252,\n",
       " 1.0212068557739258,\n",
       " 1.0196912288665771,\n",
       " 1.0207836627960205,\n",
       " 1.0220831632614136,\n",
       " 1.0237218141555786,\n",
       " 1.0127229690551758,\n",
       " 1.0109727382659912]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_fine.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "PpA8PlpQKygw"
   },
   "outputs": [],
   "source": [
    "mse += history_fine.history['mse']\n",
    "val_mse += history_fine.history['val_mse']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Igm8aMrLyFVj"
   },
   "outputs": [],
   "source": [
    "mse = mse[1:]\n",
    "val_mse = val_mse[1:]\n",
    "loss = loss[1:]\n",
    "val_loss = val_loss[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "chW103JUItdk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(mse, label='Training MSE')\n",
    "plt.plot(val_mse, label='Validation MSE')\n",
    "plt.ylim([0, 30])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Fine Tuning starts')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 5])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Fine Tuning Starts')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TZTwG7nhm0C"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "* **Using a pre-trained model for feature extraction**:  When working with a small dataset, it is a common practice to take advantage of features learned by a model trained on a larger dataset in the same domain. This is done by instantiating the pre-trained model and adding a fully-connected classifier on top. The pre-trained model is \"frozen\" and only the weights of the classifier get updated during training.\n",
    "In this case, the convolutional base extracted all the features associated with each image and you just trained a classifier that determines the image class given that set of extracted features.\n",
    "\n",
    "* **Fine-tuning a pre-trained model**: To further improve performance, one might want to repurpose the top-level layers of the pre-trained models to the new dataset via fine-tuning.\n",
    "In this case, you tuned your weights such that your model learned high-level features specific to the dataset. This technique is usually recommended when the training dataset is large and very similar to the original dataset that the pre-trained model was trained on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "eQy9mVkuoFWj"
   },
   "outputs": [],
   "source": [
    "if isGoogleColab():\n",
    "    !ls -l \"/content/drive/MyDrive/Healthcare/Radioterapia/data/ciolaplata/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "f4tr0VXGyFVr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best saved model file = /hdd/data/radioterapia/ciolaplata/models/1613153013.resnet18.23456.h5\n"
     ]
    }
   ],
   "source": [
    "print(f'Best saved model file = {callbackObj.saved_model_file}')\n",
    "saved_model = callbackObj.saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "esaw0xjhyFVv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 1s - loss: 0.2295 - mean_squared_error: 0.0836\n",
      "Saved model, train loss: 0.2295\n",
      "Saved model, train mse: 0.0836\n",
      "\n",
      "10/10 - 0s - loss: 0.8097 - mean_squared_error: 1.0479\n",
      "Saved model, validation loss: 0.8097\n",
      "Saved model, validation mse: 1.0479\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the saved model on the train set which differs from values reported during training\n",
    "loss, mse = saved_model.evaluate(tmp_train_batches, verbose=2)\n",
    "print(\"Saved model, train loss: {:5.4f}\".format(loss))\n",
    "print('Saved model, train mse: {:5.4f}\\n'.format(mse))\n",
    "\n",
    "# Evaluate the saved model on the validation set which differs from values reported during training\n",
    "loss, mse = saved_model.evaluate(tmp_validation_batches, verbose=2)\n",
    "print(\"Saved model, validation loss: {:5.4f}\".format(loss))\n",
    "print('Saved model, validation mse: {:5.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "qACCSCEAyFVz"
   },
   "outputs": [],
   "source": [
    "#result_batch = model.predict(tmp_train_batches)\n",
    "#reloaded_result_batch = reloaded_model.predict(tmp_train_batches)\n",
    "#print(abs(reloaded_result_batch - result_batch).max())\n",
    "#np.testing.assert_allclose(result_batch, reloaded_result_batch, rtol=1e-6, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "kcEpqDWFyFV4"
   },
   "outputs": [],
   "source": [
    "# projects out just the first two components.\n",
    "if ARG_TEST_PARTITION:\n",
    "    tmp_test_batches = test_batches.map(lambda image, gamma, filename: (image, gamma))\n",
    "    print(tmp_test_batches)\n",
    "\n",
    "    # Evaluate the reloaded model on the test set\n",
    "    loss, mse = saved_model.evaluate(tmp_test_batches, verbose=1)\n",
    "    print(\"\\n\\nSaved model, test loss: {:5.4f}\".format(loss))\n",
    "    print('Saved model, test mse: {:5.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "R1oRiBayRPVt"
   },
   "outputs": [],
   "source": [
    "if isGoogleColab():\n",
    "    drive.flush_and_unmount()\n",
    "    print('All changes made in this colab session should now be visible in Drive.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "transfer_learning.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
